\BOOKMARK [0][-]{chapter.1}{Preface}{}% 1
\BOOKMARK [1][-]{section.1.1}{Design\040philosophy\040of\040this\040document}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Foreword\040to\040the\040First\040Edition}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{Foreword\040to\040the\0402nd\040Edition}{chapter.1}% 4
\BOOKMARK [0][-]{chapter.2}{Introduction}{}% 5
\BOOKMARK [1][-]{section.2.1}{Why\040speech\040processing?}{chapter.2}% 6
\BOOKMARK [2][-]{subsection.2.1.1}{Why\040speech?}{section.2.1}% 7
\BOOKMARK [2][-]{subsection.2.1.2}{Early\040communications\040technology}{section.2.1}% 8
\BOOKMARK [2][-]{subsection.2.1.3}{Evolution\040of\040speech\040technology}{section.2.1}% 9
\BOOKMARK [2][-]{subsection.2.1.4}{Further\040development}{section.2.1}% 10
\BOOKMARK [1][-]{section.2.2}{Physiological\040speech\040production}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.2.1}{Overview}{section.2.2}% 12
\BOOKMARK [2][-]{subsection.2.2.2}{The\040vocal\040folds}{section.2.2}% 13
\BOOKMARK [2][-]{subsection.2.2.3}{The\040vocal\040tract}{section.2.2}% 14
\BOOKMARK [1][-]{section.2.3}{Acoustic\040properties\040of\040speech\040signals}{chapter.2}% 15
\BOOKMARK [1][-]{section.2.4}{Physiological\040modelling}{chapter.2}% 16
\BOOKMARK [2][-]{subsection.2.4.1}{Vocal\040tract}{section.2.4}% 17
\BOOKMARK [3][-]{subsubsection*.3}{Simple\040models}{subsection.2.4.1}% 18
\BOOKMARK [3][-]{subsubsection*.4}{Advanced\040models}{subsection.2.4.1}% 19
\BOOKMARK [2][-]{subsection.2.4.2}{Glottal\040activity}{section.2.4}% 20
\BOOKMARK [2][-]{subsection.2.4.3}{Lip\040radiation}{section.2.4}% 21
\BOOKMARK [1][-]{section.2.5}{Linguistic\040structure\040of\040speech}{chapter.2}% 22
\BOOKMARK [2][-]{subsection.2.5.1}{Overview}{section.2.5}% 23
\BOOKMARK [2][-]{subsection.2.5.2}{Elementary\040units\040of\040spoken\040language}{section.2.5}% 24
\BOOKMARK [3][-]{subsubsection*.5}{Phones}{subsection.2.5.2}% 25
\BOOKMARK [4][-]{paragraph*.6}{Phones\040vs.\040phonemes}{subsubsection*.5}% 26
\BOOKMARK [3][-]{subsubsection*.7}{Syllables}{subsection.2.5.2}% 27
\BOOKMARK [3][-]{subsubsection*.8}{Words}{subsection.2.5.2}% 28
\BOOKMARK [3][-]{subsubsection*.9}{Utterances}{subsection.2.5.2}% 29
\BOOKMARK [3][-]{subsubsection*.10}{Morphological\040units}{subsection.2.5.2}% 30
\BOOKMARK [2][-]{subsection.2.5.3}{Prosody,\040aka.\040suprasegmental\040properties\040of\040speech}{section.2.5}% 31
\BOOKMARK [3][-]{subsubsection*.11}{Intonation}{subsection.2.5.3}% 32
\BOOKMARK [3][-]{subsubsection*.12}{Stress}{subsection.2.5.3}% 33
\BOOKMARK [3][-]{subsubsection*.13}{Rhythm}{subsection.2.5.3}% 34
\BOOKMARK [2][-]{subsection.2.5.4}{Phonetic\040transcription\040and\040speech\040annotation}{section.2.5}% 35
\BOOKMARK [2][-]{subsection.2.5.5}{References}{section.2.5}% 36
\BOOKMARK [1][-]{section.2.6}{Applications\040and\040systems\040structures}{chapter.2}% 37
\BOOKMARK [2][-]{subsection.2.6.1}{Applications}{section.2.6}% 38
\BOOKMARK [2][-]{subsection.2.6.2}{Systems\040structures}{section.2.6}% 39
\BOOKMARK [3][-]{subsubsection*.14}{Transmission\040and\040storage}{subsection.2.6.2}% 40
\BOOKMARK [3][-]{subsubsection*.15}{Information\040extraction}{subsection.2.6.2}% 41
\BOOKMARK [2][-]{subsection.2.6.3}{Speech\040synthesis}{section.2.6}% 42
\BOOKMARK [2][-]{subsection.2.6.4}{User-interfaces}{section.2.6}% 43
\BOOKMARK [2][-]{subsection.2.6.5}{Processing\040and\040preprocessing}{section.2.6}% 44
\BOOKMARK [3][-]{subsubsection*.16}{Voice\040activity\040detection}{subsection.2.6.5}% 45
\BOOKMARK [3][-]{subsubsection*.17}{Keyword\040spotting\040or\040Wake-word\040detection}{subsection.2.6.5}% 46
\BOOKMARK [3][-]{subsubsection*.18}{Speech\040enhancement}{subsection.2.6.5}% 47
\BOOKMARK [3][-]{subsubsection*.19}{Other\040signal\040processing}{subsection.2.6.5}% 48
\BOOKMARK [0][-]{chapter.3}{Basic\040Representations}{}% 49
\BOOKMARK [1][-]{section.3.1}{Short-time\040analysis\040of\040speech\040and\040audio\040signals}{chapter.3}% 50
\BOOKMARK [2][-]{subsection.3.1.1}{The\040speech\040signal}{section.3.1}% 51
\BOOKMARK [2][-]{subsection.3.1.2}{Sound\040example}{section.3.1}% 52
\BOOKMARK [2][-]{subsection.3.1.3}{What\040would\040be\040a\040suitable\040window\040size?}{section.3.1}% 53
\BOOKMARK [2][-]{subsection.3.1.4}{Windowing\040functions}{section.3.1}% 54
\BOOKMARK [3][-]{subsubsection*.20}{Problem}{subsection.3.1.4}% 55
\BOOKMARK [3][-]{subsubsection*.21}{Solution}{subsection.3.1.4}% 56
\BOOKMARK [2][-]{subsection.3.1.5}{Spectral\040analysis}{section.3.1}% 57
\BOOKMARK [2][-]{subsection.3.1.6}{Speech\040features\040in\040the\040spectrum}{section.3.1}% 58
\BOOKMARK [3][-]{subsubsection*.22}{Envelope}{subsection.3.1.6}% 59
\BOOKMARK [3][-]{subsubsection*.23}{Formants}{subsection.3.1.6}% 60
\BOOKMARK [3][-]{subsubsection*.24}{Fundamental\040frequency}{subsection.3.1.6}% 61
\BOOKMARK [4][-]{paragraph*.25}{Harmonics\040of\040the\040fundamental}{subsubsection*.24}% 62
\BOOKMARK [2][-]{subsection.3.1.7}{Spectrogram}{section.3.1}% 63
\BOOKMARK [3][-]{subsubsection*.26}{Exercise}{subsection.3.1.7}% 64
\BOOKMARK [3][-]{subsubsection*.27}{Accuracy}{subsection.3.1.7}% 65
\BOOKMARK [3][-]{subsubsection*.28}{Speech\040features\040visible\040in\040the\040spectrogram}{subsection.3.1.7}% 66
\BOOKMARK [2][-]{subsection.3.1.8}{Short-time\040spectral\040analysis\040summary}{section.3.1}% 67
\BOOKMARK [1][-]{section.3.2}{Short-time\040processing\040of\040speech\040signals}{chapter.3}% 68
\BOOKMARK [2][-]{subsection.3.2.1}{Overlap-add}{section.3.2}% 69
\BOOKMARK [3][-]{subsubsection*.29}{Windowing\040and\040reconstruction}{subsection.3.2.1}% 70
\BOOKMARK [3][-]{subsubsection*.30}{Windowing\040and\040processing}{subsection.3.2.1}% 71
\BOOKMARK [4][-]{paragraph*.31}{Algorithm ``Overlap-add’’}{subsubsection*.30}% 72
\BOOKMARK [3][-]{subsubsection*.32}{Overlap-add\040summary}{subsection.3.2.1}% 73
\BOOKMARK [2][-]{subsection.3.2.2}{The\040short-time\040Fourier\040transform\040\(STFT\)}{section.3.2}% 74
\BOOKMARK [1][-]{section.3.3}{Waveform}{chapter.3}% 75
\BOOKMARK [2][-]{subsection.3.3.1}{Sampling\040rate}{section.3.3}% 76
\BOOKMARK [2][-]{subsection.3.3.2}{Static\040demo}{section.3.3}% 77
\BOOKMARK [2][-]{subsection.3.3.3}{On-line\040demo}{section.3.3}% 78
\BOOKMARK [3][-]{subsubsection*.33}{Original\040sound\040sample}{subsection.3.3.3}% 79
\BOOKMARK [3][-]{subsubsection*.34}{Resampling}{subsection.3.3.3}% 80
\BOOKMARK [2][-]{subsection.3.3.4}{Accuracy\040and\040distribution\040of\040steps\040on\040the\040amplitude\040axis}{section.3.3}% 81
\BOOKMARK [3][-]{subsubsection*.35}{Linear\040quantization}{subsection.3.3.4}% 82
\BOOKMARK [3][-]{subsubsection*.36}{Logarithmic\040quantization\040and\040mu-law}{subsection.3.3.4}% 83
\BOOKMARK [2][-]{subsection.3.3.5}{Wav-files}{section.3.3}% 84
\BOOKMARK [2][-]{subsection.3.3.6}{Adaptive\040quantization,\040APCM}{section.3.3}% 85
\BOOKMARK [3][-]{subsubsection*.37}{Adaptive\040quantization\040with\040the\040feed-forward\040algorithm\040using\040an\040adaptive\040quantization\040step}{subsection.3.3.6}% 86
\BOOKMARK [3][-]{subsubsection*.38}{Adaptive\040quantization\040with\040the\040feed-forward\040algorithm\040using\040an\040adaptive\040gain\040\(compressor\)}{subsection.3.3.6}% 87
\BOOKMARK [3][-]{subsubsection*.39}{Adaptive\040quantization\040with\040the\040feed-backward\040algorithm\040using\040an\040adaptive\040quantization\040step}{subsection.3.3.6}% 88
\BOOKMARK [3][-]{subsubsection*.40}{Adaptive\040quantization\040with\040the\040feed-backward\040algorithm\040using\040an\040adaptive\040gain\040coefficient}{subsection.3.3.6}% 89
\BOOKMARK [4][-]{paragraph*.41}{Differential\040quantization\040DPCM}{subsubsection*.40}% 90
\BOOKMARK [3][-]{subsubsection*.42}{Adaptive\040and\040differential\040quantization\040with\040feed-forward}{subsection.3.3.6}% 91
\BOOKMARK [3][-]{subsubsection*.43}{Adaptive\040differential\040quantization\040with\040feed-backward}{subsection.3.3.6}% 92
\BOOKMARK [3][-]{subsubsection*.44}{Adaptive\040differential\040quantization\040w/\040adaptive\040predictor}{subsection.3.3.6}% 93
\BOOKMARK [3][-]{subsubsection*.45}{Comparison\040of\040the\040SNR\040of\040different\040quantizers\040\(not\040perceptual\)}{subsection.3.3.6}% 94
\BOOKMARK [2][-]{subsection.3.3.7}{Source\040modelling\040in\040quantization}{section.3.3}% 95
\BOOKMARK [2][-]{subsection.3.3.8}{Conclusion}{section.3.3}% 96
\BOOKMARK [2][-]{subsection.3.3.9}{Refrences}{section.3.3}% 97
\BOOKMARK [1][-]{section.3.4}{Windowing}{chapter.3}% 98
\BOOKMARK [2][-]{subsection.3.4.1}{Quick\040reference}{section.3.4}% 99
\BOOKMARK [3][-]{subsubsection*.46}{Windowing\040for\040analysis\040applications}{subsection.3.4.1}% 100
\BOOKMARK [3][-]{subsubsection*.47}{Windowing\040for\040processing\040applications;\040Overlap-add}{subsection.3.4.1}% 101
\BOOKMARK [2][-]{subsection.3.4.2}{Comprehensive\040description}{section.3.4}% 102
\BOOKMARK [3][-]{subsubsection*.48}{CELP\040windowing}{subsection.3.4.2}% 103
\BOOKMARK [3][-]{subsubsection*.49}{Conclusion}{subsection.3.4.2}% 104
\BOOKMARK [1][-]{section.3.5}{Signal\040energy,\040loudness\040and\040decibel}{chapter.3}% 105
\BOOKMARK [2][-]{subsection.3.5.1}{Signal\040energy}{section.3.5}% 106
\BOOKMARK [2][-]{subsection.3.5.2}{Decibel}{section.3.5}% 107
\BOOKMARK [3][-]{subsubsection*.50}{Energy\040normalisation,\040loudness,\040dBFS\040and\040dBov}{subsection.3.5.2}% 108
\BOOKMARK [1][-]{section.3.6}{Spectrogram\040and\040the\040STFT}{chapter.3}% 109
\BOOKMARK [1][-]{section.3.7}{Autocorrelation\040and\040autocovariance}{chapter.3}% 110
\BOOKMARK [1][-]{section.3.8}{The\040cepstrum,\040mel-cepstrum\040and\040mel-frequency\040cepstral\040coefficients\040\(MFCCs\)}{chapter.3}% 111
\BOOKMARK [2][-]{subsection.3.8.1}{The\040cepstrum}{section.3.8}% 112
\BOOKMARK [2][-]{subsection.3.8.2}{Features\040in\040the\040Cepstrum}{section.3.8}% 113
\BOOKMARK [2][-]{subsection.3.8.3}{Down-sampling\040the\040log-spectrum}{section.3.8}% 114
\BOOKMARK [2][-]{subsection.3.8.4}{Mel-scale}{section.3.8}% 115
\BOOKMARK [3][-]{subsubsection*.51}{The\040Mel-Frequency\040Cepstral\040Coefficients\040\(MFCCs\)}{subsection.3.8.4}% 116
\BOOKMARK [2][-]{subsection.3.8.5}{Conclusion}{section.3.8}% 117
\BOOKMARK [1][-]{section.3.9}{Linear\040prediction}{chapter.3}% 118
\BOOKMARK [2][-]{subsection.3.9.1}{Definition}{section.3.9}% 119
\BOOKMARK [2][-]{subsection.3.9.2}{Vector\040notation}{section.3.9}% 120
\BOOKMARK [2][-]{subsection.3.9.3}{Parameter\040estimation}{section.3.9}% 121
\BOOKMARK [2][-]{subsection.3.9.4}{Spectral\040properties}{section.3.9}% 122
\BOOKMARK [2][-]{subsection.3.9.5}{Physiological\040interpretation\040and\040model\040order}{section.3.9}% 123
\BOOKMARK [2][-]{subsection.3.9.6}{Uses\040in\040speech\040coding}{section.3.9}% 124
\BOOKMARK [2][-]{subsection.3.9.7}{Alternative\040representations\040\(advanced\040topic\)}{section.3.9}% 125
\BOOKMARK [1][-]{section.3.10}{Fundamental\040frequency\040\(F0\)}{chapter.3}% 126
\BOOKMARK [1][-]{section.3.11}{Zero-crossing\040rate}{chapter.3}% 127
\BOOKMARK [1][-]{section.3.12}{Deltas\040and\040Delta-deltas}{chapter.3}% 128
\BOOKMARK [1][-]{section.3.13}{Pitch-Synchoronous\040Overlap-Add\040\(PSOLA\)}{chapter.3}% 129
\BOOKMARK [1][-]{section.3.14}{Jitter\040and\040shimmer}{chapter.3}% 130
\BOOKMARK [0][-]{chapter.4}{Pre-processing}{}% 131
\BOOKMARK [1][-]{section.4.1}{Pre-emphasis}{chapter.4}% 132
\BOOKMARK [1][-]{section.4.2}{References}{chapter.4}% 133
\BOOKMARK [0][-]{chapter.5}{Modelling\040tools\040in\040speech\040processing}{}% 134
\BOOKMARK [1][-]{section.5.1}{Source\040modelling\040and\040perceptual\040modelling}{chapter.5}% 135
\BOOKMARK [1][-]{section.5.2}{Linear\040regression}{chapter.5}% 136
\BOOKMARK [2][-]{subsection.5.2.1}{Problem\040definition}{section.5.2}% 137
\BOOKMARK [2][-]{subsection.5.2.2}{The\040minimum\040mean\040square\040estimate\040\(MMSE\)}{section.5.2}% 138
\BOOKMARK [3][-]{subsubsection*.52}{Estimates\040with\040a\040mean\040parameter}{subsection.5.2.2}% 139
\BOOKMARK [3][-]{subsubsection*.53}{Estimates\040with\040linear\040equality\040constraints}{subsection.5.2.2}% 140
\BOOKMARK [2][-]{subsection.5.2.3}{Some\040applications}{section.5.2}% 141
\BOOKMARK [2][-]{subsection.5.2.4}{Discussion}{section.5.2}% 142
\BOOKMARK [1][-]{section.5.3}{Sub-space\040models}{chapter.5}% 143
\BOOKMARK [2][-]{subsection.5.3.1}{Application\040with\040known\040sub-space}{section.5.3}% 144
\BOOKMARK [2][-]{subsection.5.3.2}{Estimation\040of\040unknown\040sub-space}{section.5.3}% 145
\BOOKMARK [2][-]{subsection.5.3.3}{Discussion}{section.5.3}% 146
\BOOKMARK [1][-]{section.5.4}{Vector\040quantization\040\(VQ\)}{chapter.5}% 147
\BOOKMARK [2][-]{subsection.5.4.1}{Metric\040for\040codebook\040quality}{section.5.4}% 148
\BOOKMARK [2][-]{subsection.5.4.2}{Codebook\040optimization}{section.5.4}% 149
\BOOKMARK [3][-]{subsubsection*.54}{Expectation\040maximization\040\(EM\)}{subsection.5.4.2}% 150
\BOOKMARK [3][-]{subsubsection*.55}{Optimization\040with\040machine\040learning\040platforms}{subsection.5.4.2}% 151
\BOOKMARK [2][-]{subsection.5.4.3}{Algorithmic\040complexity}{section.5.4}% 152
\BOOKMARK [2][-]{subsection.5.4.4}{Applications}{section.5.4}% 153
\BOOKMARK [2][-]{subsection.5.4.5}{Discussion}{section.5.4}% 154
\BOOKMARK [1][-]{section.5.5}{Gaussian\040mixture\040model\040\(GMM\)}{chapter.5}% 155
\BOOKMARK [2][-]{subsection.5.5.1}{Motivation}{section.5.5}% 156
\BOOKMARK [2][-]{subsection.5.5.2}{Model\040definition}{section.5.5}% 157
\BOOKMARK [2][-]{subsection.5.5.3}{Applications}{section.5.5}% 158
\BOOKMARK [1][-]{section.5.6}{Neural\040networks}{chapter.5}% 159
\BOOKMARK [2][-]{subsection.5.6.1}{Introduction}{section.5.6}% 160
\BOOKMARK [2][-]{subsection.5.6.2}{Network\040structures}{section.5.6}% 161
\BOOKMARK [3][-]{subsubsection*.56}{Deep\040Neural\040Networks\040\(DNNs\)}{subsection.5.6.2}% 162
\BOOKMARK [3][-]{subsubsection*.57}{Basics\040of\040Neural\040Networks}{subsection.5.6.2}% 163
\BOOKMARK [3][-]{subsubsection*.58}{Activation\040Functions:}{subsection.5.6.2}% 164
\BOOKMARK [3][-]{subsubsection*.59}{Convolutional\040neural\040networks}{subsection.5.6.2}% 165
\BOOKMARK [3][-]{subsubsection*.60}{Recurrent\040neural\040networks\040\(RNNs\)}{subsection.5.6.2}% 166
\BOOKMARK [2][-]{subsection.5.6.3}{References:}{section.5.6}% 167
\BOOKMARK [1][-]{section.5.7}{Non-negative\040Matrix\040and\040Tensor\040Factorization}{chapter.5}% 168
\BOOKMARK [2][-]{subsection.5.7.1}{Introduction}{section.5.7}% 169
\BOOKMARK [2][-]{subsection.5.7.2}{Model\040definition}{section.5.7}% 170
\BOOKMARK [2][-]{subsection.5.7.3}{Application}{section.5.7}% 171
\BOOKMARK [0][-]{chapter.6}{Evaluation\040of\040speech\040processing\040methods}{}% 172
\BOOKMARK [1][-]{section.6.1}{Subjective\040quality\040evaluation}{chapter.6}% 173
\BOOKMARK [2][-]{subsection.6.1.1}{Aspects\040of\040quality}{section.6.1}% 174
\BOOKMARK [3][-]{subsubsection*.61}{Sound\040and\040speech\040quality}{subsection.6.1.1}% 175
\BOOKMARK [3][-]{subsubsection*.62}{Interaction\040quality}{subsection.6.1.1}% 176
\BOOKMARK [2][-]{subsection.6.1.2}{Choosing subjects - Naïve or expert?}{section.6.1}% 177
\BOOKMARK [2][-]{subsection.6.1.3}{Experimental\040design}{section.6.1}% 178
\BOOKMARK [2][-]{subsection.6.1.4}{Some\040use\040cases}{section.6.1}% 179
\BOOKMARK [2][-]{subsection.6.1.5}{Frequently\040used\040standards\040and\040recommendations\040for\040quality\040evaluation}{section.6.1}% 180
\BOOKMARK [3][-]{subsubsection*.63}{Expert\040listeners}{subsection.6.1.5}% 181
\BOOKMARK [3][-]{subsubsection*.64}{Naïve listeners}{subsection.6.1.5}% 182
\BOOKMARK [2][-]{subsection.6.1.6}{Intelligibility\040testing}{section.6.1}% 183
\BOOKMARK [1][-]{section.6.2}{Objective\040quality\040evaluation}{chapter.6}% 184
\BOOKMARK [2][-]{subsection.6.2.1}{Objective\040estimators\040for\040perceptual\040quality}{section.6.2}% 185
\BOOKMARK [2][-]{subsection.6.2.2}{Other\040objective\040performance\040criteria}{section.6.2}% 186
\BOOKMARK [1][-]{section.6.3}{Other\040performance\040measures}{chapter.6}% 187
\BOOKMARK [2][-]{subsection.6.3.1}{Computational\040Complexity}{section.6.3}% 188
\BOOKMARK [3][-]{subsubsection*.65}{Big-O\040notation:}{subsection.6.3.1}% 189
\BOOKMARK [3][-]{subsubsection*.66}{Weighted Million Operations Per Second \(WMOPS\),   ITU-T. Software tool library: User’s manual, 2009 }{subsection.6.3.1}% 190
\BOOKMARK [1][-]{section.6.4}{Analysis\040of\040evaluation\040results}{chapter.6}% 191
\BOOKMARK [2][-]{subsection.6.4.1}{Informal\040analysis}{section.6.4}% 192
\BOOKMARK [3][-]{subsubsection*.67}{Example\0401}{subsection.6.4.1}% 193
\BOOKMARK [3][-]{subsubsection*.68}{Informative\040illustrations\0401}{subsection.6.4.1}% 194
\BOOKMARK [4][-]{paragraph*.69}{Histograms}{subsubsection*.68}% 195
\BOOKMARK [4][-]{paragraph*.70}{Scatter\040plots}{subsubsection*.68}% 196
\BOOKMARK [4][-]{paragraph*.71}{Box\040plots}{subsubsection*.68}% 197
\BOOKMARK [4][-]{paragraph*.72}{Confusion\040matrix}{subsubsection*.68}% 198
\BOOKMARK [3][-]{subsubsection*.73}{Example\0402}{subsection.6.4.1}% 199
\BOOKMARK [3][-]{subsubsection*.74}{Informative\040illustrations\0402}{subsection.6.4.1}% 200
\BOOKMARK [4][-]{paragraph*.75}{Parallel\040plots}{subsubsection*.74}% 201
\BOOKMARK [3][-]{subsubsection*.76}{Extracting\040hidden\040structures}{subsection.6.4.1}% 202
\BOOKMARK [4][-]{paragraph*.77}{Deltas}{subsubsection*.76}% 203
\BOOKMARK [2][-]{subsection.6.4.2}{Statistical\040tests}{section.6.4}% 204
\BOOKMARK [3][-]{subsubsection*.78}{Student’s t-test}{subsection.6.4.2}% 205
\BOOKMARK [3][-]{subsubsection*.79}{Normality\040tests}{subsection.6.4.2}% 206
\BOOKMARK [3][-]{subsubsection*.80}{ANOVA}{subsection.6.4.2}% 207
\BOOKMARK [3][-]{subsubsection*.81}{Correlation\040tests}{subsection.6.4.2}% 208
\BOOKMARK [0][-]{chapter.7}{Speech\040analysis}{}% 209
\BOOKMARK [1][-]{section.7.1}{Fundamental\040frequency\040estimation}{chapter.7}% 210
\BOOKMARK [1][-]{section.7.2}{Measurements\040for\040medical\040applications}{chapter.7}% 211
\BOOKMARK [2][-]{subsection.7.2.1}{Inverse\040filtering\040for\040glottal\040activity\040estimation}{section.7.2}% 212
\BOOKMARK [3][-]{subsubsection*.82}{Motivation}{subsection.7.2.1}% 213
\BOOKMARK [3][-]{subsubsection*.83}{Signal\040Model}{subsection.7.2.1}% 214
\BOOKMARK [1][-]{section.7.3}{Forensic\040analysis}{chapter.7}% 215
\BOOKMARK [0][-]{chapter.8}{Recognition\040tasks\040in\040speech\040processing}{}% 216
\BOOKMARK [1][-]{section.8.1}{Voice\040Activity\040Detection\040\(VAD\)}{chapter.8}% 217
\BOOKMARK [2][-]{subsection.8.1.1}{Introduction}{section.8.1}% 218
\BOOKMARK [2][-]{subsection.8.1.2}{Low-noise\040VAD\040=\040Trivial\040case}{section.8.1}% 219
\BOOKMARK [2][-]{subsection.8.1.3}{VAD\040objective\040and\040performance\040measurement}{section.8.1}% 220
\BOOKMARK [3][-]{subsubsection*.84}{Performance in noise – -3dB / -4dB threshold}{subsection.8.1.3}% 221
\BOOKMARK [2][-]{subsection.8.1.4}{Post-processing}{section.8.1}% 222
\BOOKMARK [2][-]{subsection.8.1.5}{VAD\040for\040noisy\040speech}{section.8.1}% 223
\BOOKMARK [3][-]{subsubsection*.85}{Features}{subsection.8.1.5}% 224
\BOOKMARK [2][-]{subsection.8.1.6}{Classifier}{section.8.1}% 225
\BOOKMARK [3][-]{subsubsection*.86}{Decision\040trees\040\(historical\)}{subsection.8.1.6}% 226
\BOOKMARK [3][-]{subsubsection*.87}{Linear\040classifier}{subsection.8.1.6}% 227
\BOOKMARK [4][-]{paragraph*.88}{A\040bit\040of\040math}{subsubsection*.87}% 228
\BOOKMARK [4][-]{paragraph*.89}{Pre-whitening\040\(advanced\040topic\)}{subsubsection*.87}% 229
\BOOKMARK [3][-]{subsubsection*.90}{Post-processing}{subsection.8.1.6}% 230
\BOOKMARK [3][-]{subsubsection*.91}{More\040advanced\040classifiers}{subsection.8.1.6}% 231
\BOOKMARK [2][-]{subsection.8.1.7}{Speech\040Presence\040Probability}{section.8.1}% 232
\BOOKMARK [3][-]{subsubsection*.92}{Output\040before\040thresholding}{subsection.8.1.7}% 233
\BOOKMARK [2][-]{subsection.8.1.8}{Noise\040types}{section.8.1}% 234
\BOOKMARK [2][-]{subsection.8.1.9}{Conclusions}{section.8.1}% 235
\BOOKMARK [1][-]{section.8.2}{Wake-word\040and\040keyword\040spotting}{chapter.8}% 236
\BOOKMARK [2][-]{subsection.8.2.1}{References}{section.8.2}% 237
\BOOKMARK [1][-]{section.8.3}{Speech\040Recognition}{chapter.8}% 238
\BOOKMARK [2][-]{subsection.8.3.1}{Introduction\040to\040ASR}{section.8.3}% 239
\BOOKMARK [2][-]{subsection.8.3.2}{Component\040of\040ASR}{section.8.3}% 240
\BOOKMARK [2][-]{subsection.8.3.3}{Types\040of\040ASR}{section.8.3}% 241
\BOOKMARK [2][-]{subsection.8.3.4}{Models\040for\040Large\040Vocabulary\040Speech\040Recognition\040\(LVCSR\)}{section.8.3}% 242
\BOOKMARK [3][-]{subsubsection*.93}{HMM-Based\040Model}{subsection.8.3.4}% 243
\BOOKMARK [3][-]{subsubsection*.94}{End-to-End\040Model}{subsection.8.3.4}% 244
\BOOKMARK [2][-]{subsection.8.3.5}{Types\040of\040errors\040made\040by\040speech\040recognizers}{section.8.3}% 245
\BOOKMARK [2][-]{subsection.8.3.6}{Challenges\040of\040ASR}{section.8.3}% 246
\BOOKMARK [2][-]{subsection.8.3.7}{Evaluation}{section.8.3}% 247
\BOOKMARK [3][-]{subsubsection*.95}{References}{subsection.8.3.7}% 248
\BOOKMARK [1][-]{section.8.4}{Speaker\040Recognition\040and\040Verification}{chapter.8}% 249
\BOOKMARK [2][-]{subsection.8.4.1}{1. Introduction to Speaker Recognition}{section.8.4}% 250
\BOOKMARK [2][-]{subsection.8.4.2}{2.\040Front-end\040Processing}{section.8.4}% 251
\BOOKMARK [2][-]{subsection.8.4.3}{3. Speaker Modeling Techniques}{section.8.4}% 252
\BOOKMARK [2][-]{subsection.8.4.4}{3.1.\040Gaussian\040Mixture\040Modeling\040\(GMM\)\040-\040Universal\040Background\040Model\040\(UBM\)\040Approach}{section.8.4}% 253
\BOOKMARK [2][-]{subsection.8.4.5}{3.2.\040i-Vectors}{section.8.4}% 254
\BOOKMARK [2][-]{subsection.8.4.6}{3.3.  Deep Learning \(DL\)}{section.8.4}% 255
\BOOKMARK [2][-]{subsection.8.4.7}{4.\040Applications\040of\040Speaker\040Recognition}{section.8.4}% 256
\BOOKMARK [2][-]{subsection.8.4.8}{5.\040Performance\040Evaluations}{section.8.4}% 257
\BOOKMARK [2][-]{subsection.8.4.9}{5.1\040Types\040of\040errors}{section.8.4}% 258
\BOOKMARK [2][-]{subsection.8.4.10}{5.2\040Performance\040metrics}{section.8.4}% 259
\BOOKMARK [2][-]{subsection.8.4.11}{Attachments:}{section.8.4}% 260
\BOOKMARK [1][-]{section.8.5}{Speaker\040Diarization}{chapter.8}% 261
\BOOKMARK [2][-]{subsection.8.5.1}{1. Introduction to Speaker Diarization}{section.8.5}% 262
\BOOKMARK [2][-]{subsection.8.5.2}{2.\040Approaches\040to\040Speaker\040Diarization}{section.8.5}% 263
\BOOKMARK [2][-]{subsection.8.5.3}{3.\040Evaluation\040Metrics}{section.8.5}% 264
\BOOKMARK [1][-]{section.8.6}{Paralinguistic\040speech\040processing}{chapter.8}% 265
\BOOKMARK [2][-]{subsection.8.6.1}{Coupling\040between\040speaker\040states\040and\040the\040speech\040signal}{section.8.6}% 266
\BOOKMARK [2][-]{subsection.8.6.2}{Speaker\040traits\040and\040states}{section.8.6}% 267
\BOOKMARK [2][-]{subsection.8.6.3}{Typical\040applications\040of\040PSP}{section.8.6}% 268
\BOOKMARK [2][-]{subsection.8.6.4}{Basic\040problem\040formulation\040and\040standard\040solutions}{section.8.6}% 269
\BOOKMARK [2][-]{subsection.8.6.5}{Data\040collection\040and\040data\040sparsity}{section.8.6}% 270
\BOOKMARK [2][-]{subsection.8.6.6}{Computational\040Paralinguistic\040Challenge}{section.8.6}% 271
\BOOKMARK [2][-]{subsection.8.6.7}{Further\040reading\040and\040materials\040on\040PSP}{section.8.6}% 272
\BOOKMARK [0][-]{chapter.9}{Speech\040Synthesis}{}% 273
\BOOKMARK [1][-]{section.9.1}{Concatenative\040speech\040synthesis}{chapter.9}% 274
\BOOKMARK [2][-]{subsection.9.1.1}{Steps\040of\040concatenative\040synthesis}{section.9.1}% 275
\BOOKMARK [2][-]{subsection.9.1.2}{CSS\040training}{section.9.1}% 276
\BOOKMARK [2][-]{subsection.9.1.3}{Further\040reading}{section.9.1}% 277
\BOOKMARK [1][-]{section.9.2}{Statistical\040parametric\040speech\040synthesis}{chapter.9}% 278
\BOOKMARK [2][-]{subsection.9.2.1}{Feature\040generation}{section.9.2}% 279
\BOOKMARK [2][-]{subsection.9.2.2}{Waveform\040generation\040with\040vocoders}{section.9.2}% 280
\BOOKMARK [2][-]{subsection.9.2.3}{SPSS\040system\040training}{section.9.2}% 281
\BOOKMARK [2][-]{subsection.9.2.4}{Advantages\040and\040disadvantages\040of\040the\040HMM-GMM\040SPSS\040compared\040to\040concatenative\040synthesis}{section.9.2}% 282
\BOOKMARK [2][-]{subsection.9.2.5}{Neural\040SPSS}{section.9.2}% 283
\BOOKMARK [2][-]{subsection.9.2.6}{Further\040reading}{section.9.2}% 284
\BOOKMARK [0][-]{chapter.10}{Transmission,\040storage\040and\040telecommunication}{}% 285
\BOOKMARK [1][-]{section.10.1}{Design\040goals}{chapter.10}% 286
\BOOKMARK [2][-]{subsection.10.1.1}{References}{section.10.1}% 287
\BOOKMARK [1][-]{section.10.2}{Modified\040discrete\040cosine\040transform\040\(MDCT\)}{chapter.10}% 288
\BOOKMARK [2][-]{subsection.10.2.1}{Introduction}{section.10.2}% 289
\BOOKMARK [2][-]{subsection.10.2.2}{Executive\040summary\040of\040algorithm}{section.10.2}% 290
\BOOKMARK [2][-]{subsection.10.2.3}{Definition}{section.10.2}% 291
\BOOKMARK [2][-]{subsection.10.2.4}{References}{section.10.2}% 292
\BOOKMARK [2][-]{subsection.10.2.5}{Entropy\040coding}{section.10.2}% 293
\BOOKMARK [3][-]{subsubsection*.96}{Vector\040coding}{subsection.10.2.5}% 294
\BOOKMARK [3][-]{subsubsection*.97}{Variable\040length\040and\040Huffman\040coding}{subsection.10.2.5}% 295
\BOOKMARK [3][-]{subsubsection*.98}{Arithmetic\040coding}{subsection.10.2.5}% 296
\BOOKMARK [3][-]{subsubsection*.99}{Parametric\040coding}{subsection.10.2.5}% 297
\BOOKMARK [3][-]{subsubsection*.100}{Algebraic\040coding}{subsection.10.2.5}% 298
\BOOKMARK [2][-]{subsection.10.2.6}{Perceptual\040modelling\040in\040speech\040and\040audio\040coding}{section.10.2}% 299
\BOOKMARK [3][-]{subsubsection*.101}{Frequency\040masking}{subsection.10.2.6}% 300
\BOOKMARK [3][-]{subsubsection*.102}{Frequency\040scale}{subsection.10.2.6}% 301
\BOOKMARK [3][-]{subsubsection*.103}{Temporal\040masking}{subsection.10.2.6}% 302
\BOOKMARK [1][-]{section.10.3}{Code-excited\040linear\040prediction\040\(CELP\)}{chapter.10}% 303
\BOOKMARK [2][-]{subsection.10.3.1}{Encoder/decoder\040structure}{section.10.3}% 304
\BOOKMARK [2][-]{subsection.10.3.2}{Perceptual\040quality\040evaluation}{section.10.3}% 305
\BOOKMARK [2][-]{subsection.10.3.3}{Noise\040modelling\040and\040algebraic\040coding}{section.10.3}% 306
\BOOKMARK [1][-]{section.10.4}{Frequency-domain\040coding}{chapter.10}% 307
\BOOKMARK [0][-]{chapter.11}{Speech\040enhancement}{}% 308
\BOOKMARK [1][-]{section.11.1}{Noise\040attenuation}{chapter.11}% 309
\BOOKMARK [2][-]{subsection.11.1.1}{Noise\040gate}{section.11.1}% 310
\BOOKMARK [2][-]{subsection.11.1.2}{Statistical\040model}{section.11.1}% 311
\BOOKMARK [3][-]{subsubsection*.104}{Noise\040estimation\040and\040modelling}{subsection.11.1.2}% 312
\BOOKMARK [4][-]{paragraph*.105}{Mean-energy\040with\040voice\040activity\040detection}{subsubsection*.104}% 313
\BOOKMARK [4][-]{paragraph*.106}{Minimum\040statistics}{subsubsection*.104}% 314
\BOOKMARK [2][-]{subsection.11.1.3}{Spectral\040subtraction}{section.11.1}% 315
\BOOKMARK [2][-]{subsection.11.1.4}{Minimum-mean\040Square\040Estimate\040\(MMSE\)\040aka.\040Wiener\040filtering}{section.11.1}% 316
\BOOKMARK [3][-]{subsubsection*.107}{Treating\040musical\040noise}{subsection.11.1.4}% 317
\BOOKMARK [4][-]{paragraph*.108}{Noise\040filling}{subsubsection*.107}% 318
\BOOKMARK [4][-]{paragraph*.109}{Mapping}{subsubsection*.107}% 319
\BOOKMARK [3][-]{subsubsection*.110}{Wiener\040filtering\040for\040vectors}{subsection.11.1.4}% 320
\BOOKMARK [2][-]{subsection.11.1.5}{Masks,\040power\040spectra\040and\040temporal\040characteristics}{section.11.1}% 321
\BOOKMARK [2][-]{subsection.11.1.6}{Machine\040learning\040methods}{section.11.1}% 322
\BOOKMARK [2][-]{subsection.11.1.7}{References}{section.11.1}% 323
\BOOKMARK [1][-]{section.11.2}{Echo\040cancellation}{chapter.11}% 324
\BOOKMARK [2][-]{subsection.11.2.1}{Echo\040cancellation\040solutions}{section.11.2}% 325
\BOOKMARK [1][-]{section.11.3}{Bandwidth\040extension\040\(BWE\)}{chapter.11}% 326
\BOOKMARK [1][-]{section.11.4}{Multi-channel\040speech\040enhancement\040and\040beamforming}{chapter.11}% 327
\BOOKMARK [2][-]{subsection.11.4.1}{Delay-and-sum\040beamforming}{section.11.4}% 328
\BOOKMARK [0][-]{chapter.12}{Computational\040models\040of\040human\040language\040processing}{}% 329
\BOOKMARK [1][-]{section.12.1}{Human\040cognition\040as\040a\040sensorimotor\040information\040processing\040system}{chapter.12}% 330
\BOOKMARK [2][-]{subsection.12.1.1}{Computational\040modeling\040versus\040cognitive\040computationalism}{section.12.1}% 331
\BOOKMARK [1][-]{section.12.2}{Role\040of\040computational\040models\040in\040scientific\040research}{chapter.12}% 332
\BOOKMARK [1][-]{section.12.3}{Examples\040of\040computational\040modeling\040research}{chapter.12}% 333
\BOOKMARK [1][-]{section.12.4}{References\040and\040further\040reading}{chapter.12}% 334
\BOOKMARK [0][-]{chapter.13}{Security\040and\040privacy\040in\040speech\040technology}{}% 335
\BOOKMARK [1][-]{section.13.1}{System\040models}{chapter.13}% 336
\BOOKMARK [2][-]{subsection.13.1.1}{All-human\040interaction}{section.13.1}% 337
\BOOKMARK [3][-]{subsubsection*.111}{Primary\040interaction}{subsection.13.1.1}% 338
\BOOKMARK [3][-]{subsubsection*.112}{Secondary\040interactions}{subsection.13.1.1}% 339
\BOOKMARK [3][-]{subsubsection*.113}{Ownership\040and\040personal\040privacy}{subsection.13.1.1}% 340
\BOOKMARK [2][-]{subsection.13.1.2}{Interactions\040which\040involve\040devices\040or\040services}{section.13.1}% 341
\BOOKMARK [3][-]{subsubsection*.114}{Telecommunication}{subsection.13.1.2}% 342
\BOOKMARK [3][-]{subsubsection*.115}{Discussion\040in\040the\040presence\040of\040speech\040interfaces}{subsection.13.1.2}% 343
\BOOKMARK [3][-]{subsubsection*.116}{Interaction\040with\040a\040speech\040interface}{subsection.13.1.2}% 344
\BOOKMARK [3][-]{subsubsection*.117}{Multi-user\040interaction\040with\040a\040speech\040interface}{subsection.13.1.2}% 345
\BOOKMARK [3][-]{subsubsection*.118}{Interaction\040with\040a\040speech\040interface\040in\040the\040presence\040of\040others}{subsection.13.1.2}% 346
\BOOKMARK [3][-]{subsubsection*.119}{Interaction\040with\040a\040speech\040interface\040connected\040to\040other\040services}{subsection.13.1.2}% 347
\BOOKMARK [2][-]{subsection.13.1.3}{Multi-user\040and\040multi-device\040scenarios}{section.13.1}% 348
\BOOKMARK [1][-]{section.13.2}{Information\040contained\040in\040speech\040signals}{chapter.13}% 349
\BOOKMARK [1][-]{section.13.3}{Types\040of\040privacy}{chapter.13}% 350
\BOOKMARK [1][-]{section.13.4}{Threat\040and\040attack\040scenarios}{chapter.13}% 351
\BOOKMARK [1][-]{section.13.5}{Privacy\040and\040security\040scandals}{chapter.13}% 352
\BOOKMARK [1][-]{section.13.6}{Approaches\040for\040safeguarding\040privacy\040in\040and\040improving\040usability\040of\040speech\040technology}{chapter.13}% 353
\BOOKMARK [2][-]{subsection.13.6.1}{Basic\040design\040concepts}{section.13.6}% 354
\BOOKMARK [2][-]{subsection.13.6.2}{Definitions}{section.13.6}% 355
\BOOKMARK [2][-]{subsection.13.6.3}{Local/edge\040processing}{section.13.6}% 356
\BOOKMARK [2][-]{subsection.13.6.4}{Differential\040privacy}{section.13.6}% 357
\BOOKMARK [2][-]{subsection.13.6.5}{Federated\040learning}{section.13.6}% 358
\BOOKMARK [2][-]{subsection.13.6.6}{Homomorphic\040encryption}{section.13.6}% 359
\BOOKMARK [2][-]{subsection.13.6.7}{myData}{section.13.6}% 360
\BOOKMARK [1][-]{section.13.7}{Design\040goals,\040human\040computer\040interfaces\040and\040user\040experience}{chapter.13}% 361
\BOOKMARK [1][-]{section.13.8}{Ethical\040dilemmas}{chapter.13}% 362
\BOOKMARK [1][-]{section.13.9}{Security\040and\040privacy\040in\040speech\040research}{chapter.13}% 363
\BOOKMARK [1][-]{section.13.10}{References}{chapter.13}% 364
\BOOKMARK [0][-]{chapter.14}{References}{}% 365
\BOOKMARK [0][-]{chapter*.120}{Bibliography}{}% 366
