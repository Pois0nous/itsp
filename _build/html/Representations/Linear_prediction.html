
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.9. Linear prediction &#8212; Introduction to Speech Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.10. Fundamental frequency (F0)" href="Fundamental_frequency_F0.html" />
    <link rel="prev" title="3.8. The cepstrum, mel-cepstrum and mel-frequency cepstral coefficients (MFCCs)" href="Melcepstrum.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Speech Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Introduction to Speech Processing
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Preface.html">
   1. Preface
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Introduction.html">
   2. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Why_speech_processing.html">
     2.1. Why speech processing?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Speech_production_and_acoustic_properties.html">
     2.2. Physiological speech production
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Speech_perception">
     Speech perception (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Linguistic_structure_of_speech.html">
     2.5. Linguistic structure of speech
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Speech-language_pathology">
     Speech-language pathology (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Applications_and_systems_structures.html">
     2.6. Applications and systems structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="http://pressbooks-dev.oer.hawaii.edu/messageprocessing/">
     Social and cognitive processes in human communication (external)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Representations.html">
   3. Basic Representations
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Short-time_analysis.html">
     3.1. Short-time analysis of speech and audio signals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Short-time_processing.html">
     3.2. Short-time processing of speech signals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Waveform.html">
     3.3. Waveform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Windowing.html">
     3.4. Windowing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Signal_energy_loudness_and_decibel.html">
     3.5. Signal energy, loudness and decibel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Spectrogram_and_the_STFT.html">
     3.6. Spectrogram and the STFT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Autocorrelation_and_autocovariance.html">
     3.7. Autocorrelation and autocovariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Melcepstrum.html">
     3.8. The cepstrum, mel-cepstrum and mel-frequency cepstral coefficients (MFCCs)
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.9. Linear prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Fundamental_frequency_F0.html">
     3.10. Fundamental frequency (F0)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Zero-crossing_rate.html">
     3.11. Zero-crossing rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Deltas_and_Delta-deltas.html">
     3.12. Deltas and Delta-deltas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Pitch-Synchoronous_Overlap-Add_PSOLA.html">
     3.13. Pitch-Synchoronous Overlap-Add (PSOLA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Jitter_and_shimmer.html">
     3.14. Jitter and shimmer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Crest_factor">
     https://en.wikipedia.org/wiki/Crest_factor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Pre-processing.html">
   4. Pre-processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Preprocessing/Pre-emphasis.html">
     4.1. Pre-emphasis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Noise_gate">
     Noise gate (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Dynamic_range_compression">
     Dynamic Range Compression (Wikipedia)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Modelling_tools_in_speech_processing.html">
   5. Modelling tools in speech processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Modelling/Source_modelling_and_perceptual_modelling.html">
     5.1. Source modelling and perceptual modelling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Modelling/Linear_regression.html">
     5.2. Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Modelling/Sub-space_models.html">
     5.3. Sub-space models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Modelling/Vector_quantization_VQ.html">
     5.4. Vector quantization (VQ)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Modelling/Gaussian_mixture_model_GMM.html">
     5.5. Gaussian mixture model (GMM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Modelling/Neural_networks.html">
     5.6. Neural networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Modelling/Non-negative_Matrix_and_Tensor_Factorization.html">
     5.7. Non-negative Matrix and Tensor Factorization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Evaluation_of_speech_processing_methods.html">
   6. Evaluation of speech processing methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Subjective_quality_evaluation.html">
     6.1. Subjective quality evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Objective_quality_evaluation.html">
     6.2. Objective quality evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Other_performance_measures.html">
     6.3. Other performance measures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Analysis_of_evaluation_results.html">
     6.4. Analysis of evaluation results
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_analysis.html">
   7. Speech analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Analysis/Fundamental_frequency_estimation.html">
     7.1. Fundamental frequency estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Voice_analysis">
     Voice and speech analysis (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Analysis/Measurements_for_medical_applications.html">
     7.2. Measurements for medical applications
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference external" href="https://en.wikipedia.org/wiki/Electroglottograph">
       Electroglottography (Wikipedia)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference external" href="https://en.wikipedia.org/wiki/Videokymography">
       Videokymography (Wikipedia)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Analysis/Inverse_filtering_for_glottal_activity_estimation.html">
       7.2.1. Inverse filtering for glottal activity estimation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Analysis/Forensic_analysis.html">
     7.3. Forensic analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Recognition_tasks_in_speech_processing.html">
   8. Recognition tasks in speech processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Voice_activity_detection.html">
     8.1. Voice Activity Detection (VAD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Wake-word_and_keyword_spotting.html">
     8.2. Wake-word and keyword spotting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speech_Recognition.html">
     8.3. Speech Recognition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speaker_Recognition_and_Verification.html">
     8.4. Speaker Recognition and Verification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speaker_Diarization.html">
     8.5. Speaker Diarization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Paralinguistic_speech_processing.html">
     8.6. Paralinguistic speech processing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_Synthesis.html">
   9. Speech Synthesis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Synthesis/Concatenative_speech_synthesis.html">
     9.1. Concatenative speech synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Synthesis/Statistical_parametric_speech_synthesis.html">
     9.2. Statistical parametric speech synthesis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Transmission_storage_and_telecommunication.html">
   10. Transmission, storage and telecommunication
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Design_goals.html">
     10.1. Design goals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Basic_tools.html">
     10.2. Basic tools
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Transmission/Modified_discrete_cosine_transform_MDCT.html">
     10.3. Modified discrete cosine transform (MDCT)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transmission/Entropy_coding.html">
       10.3.4. Entropy coding
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transmission/Perceptual_modelling_in_speech_and_audio_coding.html">
       10.3.5. Perceptual modelling in speech and audio coding
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Code-excited_linear_prediction_CELP.html">
     10.4. Code-excited linear prediction (CELP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Frequency-domain_coding.html">
     10.5. Frequency-domain coding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_enhancement.html">
   11. Speech enhancement
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Noise_attenuation.html">
     11.1. Noise attenuation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Echo_cancellation.html">
     11.2. Echo cancellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Bandwidth_extension_BWE.html">
     11.3. Bandwidth extension (BWE)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Multi-channel_speech_enhancement_and_beamforming.html">
     11.4. Multi-channel speech enhancement and beamforming
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://landbot.io/blog/guide-to-conversational-design/">
   Chatbots / Conversational design (external link)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Computational_models_of_human_language_processing.html">
   12. Computational models of human language processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Security_and_privacy_in_speech_technology.html">
   13. Security and privacy in speech technology
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../References.html">
   14. References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Representations/Linear_prediction.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#definition">
   3.9.1. Definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vector-notation">
   3.9.2. Vector notation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameter-estimation">
   3.9.3. Parameter estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spectral-properties">
   3.9.4. Spectral properties
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#physiological-interpretation-and-model-order">
   3.9.5. Physiological interpretation and model order
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uses-in-speech-coding">
   3.9.6. Uses in speech coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-representations-advanced-topic">
   3.9.7. Alternative representations (advanced topic)
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Linear prediction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#definition">
   3.9.1. Definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vector-notation">
   3.9.2. Vector notation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameter-estimation">
   3.9.3. Parameter estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spectral-properties">
   3.9.4. Spectral properties
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#physiological-interpretation-and-model-order">
   3.9.5. Physiological interpretation and model order
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uses-in-speech-coding">
   3.9.6. Uses in speech coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-representations-advanced-topic">
   3.9.7. Alternative representations (advanced topic)
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="linear-prediction">
<h1><span class="section-number">3.9. </span>Linear prediction<a class="headerlink" href="#linear-prediction" title="Permalink to this headline">¶</a></h1>
<div class="section" id="definition">
<h2><span class="section-number">3.9.1. </span>Definition<a class="headerlink" href="#definition" title="Permalink to this headline">¶</a></h2>
<p>Speech is a continuous signal, which means that consecutive samples of
the signal are correlated (see figure on the right). In particular, if
we know a previous sample <span class="math notranslate nohighlight">\(x_{n-1}\)</span>, we can make a <em>prediction</em>
of the current sample, <span class="math notranslate nohighlight">\( \hat x_n = x_{n-1}, \)</span> such that <span class="math notranslate nohighlight">\( \hat
x_n \approx x_n. \)</span> By using more previous samples we have more
information, which should help us make a better prediction.
Specifically, we can define a predictor which uses <span class="math notranslate nohighlight">\(M\)</span> previous samples
to predict the current sample <span class="math notranslate nohighlight">\(x_{n }\)</span> as</p>
<div class="math notranslate nohighlight">
\[ \hat x_n = - \sum_{k=1}^M a_k x_{n-k}. \]</div>
<p>This is a <em>linear predictor</em> because it takes a linearly weighted sum of
past components to predict the current one.</p>
<p>The error of the prediction, also known as the <em>prediction residual</em> is</p>
<div class="math notranslate nohighlight">
\[ e_n = x_n - \hat x_n = x_n + \sum_{k=1}^M a_k x_{n-k} =
\sum_{k=0}^M a_k x_{n-k}, \]</div>
<p>where <span class="math notranslate nohighlight">\(a_{0}=1\)</span>. This explains why the definition <span class="math notranslate nohighlight">\( \hat x_n
\)</span> included a minus sign; when we calculate the residual, the double
negative disappears and we can collate everything into one summation.</p>
<p>A short segment of speech. Notice how consecutive samples are mostly
near each other, which means that consecutive samples are correlated.</p>
<p><img alt="speechsegment" src="../_images/149884842.png" /></p>
</div>
<div class="section" id="vector-notation">
<h2><span class="section-number">3.9.2. </span>Vector notation<a class="headerlink" href="#vector-notation" title="Permalink to this headline">¶</a></h2>
<p>Using vector notation, we can make the expressions more compact</p>
<div class="math notranslate nohighlight">
\[ e = Xa \]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split} e =
\begin{bmatrix}e_0\\e_1\\\vdots\\e_{N-1}\end{bmatrix},\qquad
X = \begin{bmatrix}x_0 &amp; x_{-1} &amp; \dots &amp; x_{M} \\x_1 &amp; x_0 &amp;
\dots &amp; x_{M-1} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ x_{N-1} &amp;
x_{N-2} &amp; \dots &amp; x_{N-M} \end{bmatrix}, \qquad a =
\begin{bmatrix}a_0\\a_1\\\vdots\\a_{M}\end{bmatrix}. \end{split}\]</div>
<p>Here we calculated the residual for a length <span class="math notranslate nohighlight">\(N\)</span> frame of the signal.</p>
</div>
<div class="section" id="parameter-estimation">
<h2><span class="section-number">3.9.3. </span>Parameter estimation<a class="headerlink" href="#parameter-estimation" title="Permalink to this headline">¶</a></h2>
<p>Vector <span class="math notranslate nohighlight">\(a\)</span> holds the unknown coefficients of the predictor. To find the
best possible predictor, we can minimize the minimum mean-square error
(MMSE). The square error is the 2-norm of the residual, <span class="math notranslate nohighlight">\(
\|e\|^2=e^T e \)</span> . The mean of that error is defined as the
expectation</p>
<div class="math notranslate nohighlight">
\[ E\left[|e|^2\right] = E\left[a^T X^T X a\right] = a^T
E\left[X^T X\right] a = a^T R_x a, \]</div>
<p>where <span class="math notranslate nohighlight">\( R_x = E\left[X^T X\right] \)</span> and <span class="math notranslate nohighlight">\(
E\left[\cdot\right] \)</span> is the expectation operator. Note that, as
shown in the <a class="reference internal" href="Autocorrelation_and_autocovariance.html"><span class="doc std std-doc">autocorrelation
section</span></a>, the matrix
<span class="math notranslate nohighlight">\(R_{x}\)</span>, can be usually assumed to have a symmetric
<a class="reference external" href="https://en.wikipedia.org/wiki/Toeplitz_matrix">Toeplitz</a> structure.</p>
<p>If we would directly minimize the mean-square error  <span class="math notranslate nohighlight">\(
E\left[\|e\|^2\right], \)</span> then clearly we would obtain the
trivial solution <span class="math notranslate nohighlight">\(a=0\)</span>, which is not particularly useful. However that
solution contradicts with the requirement that the first coefficient is
unity, <span class="math notranslate nohighlight">\(a_{0}=1\)</span>. In vector notation we can equivalently write</p>
<div class="math notranslate nohighlight">
\[\begin{split} a_0-1=u^T a -1=0,
\qquad\text{where}\,u=\begin{bmatrix}1\\0\\0\\\vdots\\0\end{bmatrix}.
\end{split}\]</div>
<p>The standard method for quadratic minimization with constraints is to
use a <a class="reference external" href="https://en.wikipedia.org/wiki/Lagrange_multiplier">Langrange
multiplier</a>, λ, such
that the objective function is</p>
<div class="math notranslate nohighlight">
\[ \eta(a,\lambda) = a^T R_x a - 2\lambda\left(a^T u - 1\right).
\]</div>
<p>This function can be heuristically interpreted such that λ is a free
parameter. Since our objective is to minimize <span class="math notranslate nohighlight">\( a^T R_x a \)</span> if   <span class="math notranslate nohighlight">\(
a^T u - 1 \)</span> is non-zero, then the objective function can become
arbitrarily large. To allow any value for λ, the constraint must
therefore be zero.</p>
<p>The objective function is then minimized by setting its derivative with
respect to <span class="math notranslate nohighlight">\(a\)</span> to zero</p>
<div class="math notranslate nohighlight">
\[ 0 = \frac\partial{\partial a}\eta(a,\lambda) =
\frac\partial{\partial a} \left[a^T R_x a -2\lambda\left(a^T u -
1\right)\right] = 2 R_x a - 2 \lambda u. \]</div>
<p>It follows that the optimal predictor coefficients are found by solving</p>
<div class="math notranslate nohighlight">
\[ R_x a = \lambda u. \]</div>
<p>Since <span class="math notranslate nohighlight">\(R_{x}\)</span>, is symmetric and
<a class="reference external" href="https://en.wikipedia.org/wiki/Toeplitz_matrix">Toeplitz</a>, the above
system of equations can be efficiently solved using the <a class="reference external" href="https://en.wikipedia.org/wiki/Levinson_recursion">Levinson-Durbin
algorithm</a> with
algorithmic complexity <span class="math notranslate nohighlight">\(O(M^{2})\)</span>. However, note that with
direct solution we obtain <span class="math notranslate nohighlight">\( a':=\frac1\lambda a = R_x^{-1}u \)</span> that
is, instead of <span class="math notranslate nohighlight">\(a\)</span> we get <span class="math notranslate nohighlight">\(a\)</span> scaled with λ. However, since we know that
<span class="math notranslate nohighlight">\(a_{0}=1\)</span>, we can find <span class="math notranslate nohighlight">\(a\)</span> by <span class="math notranslate nohighlight">\( a=\lambda a' =
\frac{a'}{a'_0}. \)</span></p>
</div>
<div class="section" id="spectral-properties">
<h2><span class="section-number">3.9.4. </span>Spectral properties<a class="headerlink" href="#spectral-properties" title="Permalink to this headline">¶</a></h2>
<p>Linear prediction is usually used to predict the current sample of a
time-domain signal <span class="math notranslate nohighlight">\(x_{n}\)</span>. The usefulness of linear prediction
however becomes evident by studying its Fourier spectrum Specifically,
since <span class="math notranslate nohighlight">\(e=Xa\)</span>, the corresponding Z-domain representation is</p>
<div class="math notranslate nohighlight">
\[ E(z) = X(z)A(z)\qquad\Rightarrow\qquad X(z)=\frac{E(z)}{A(z)},
\]</div>
<p>where <span class="math notranslate nohighlight">\(E(z)\)</span>, <span class="math notranslate nohighlight">\(X(z)\)</span>, and <span class="math notranslate nohighlight">\(A(z)\)</span>, are the Z-transforms of
<span class="math notranslate nohighlight">\(e_{n}\)</span>, <span class="math notranslate nohighlight">\(x_{n}\)</span> and <span class="math notranslate nohighlight">\(a_{n}\)</span>, respectively. The
residual <span class="math notranslate nohighlight">\(E(z)\)</span> is white-noise, whereby the inverse <span class="math notranslate nohighlight">\(A(z)^{-1}\)</span>,
must follow the shape of <span class="math notranslate nohighlight">\(X(z)\)</span>.</p>
<p>In other words, the linear predictor models the macro-shape or
<em>envelope</em> of the spectrum.</p>
</div>
<div class="section" id="physiological-interpretation-and-model-order">
<h2><span class="section-number">3.9.5. </span>Physiological interpretation and model order<a class="headerlink" href="#physiological-interpretation-and-model-order" title="Permalink to this headline">¶</a></h2>
<p>Linear prediction has a surprising connection with physical modelling of
<span class="xref myst">speech production</span>. Namely,
a linear predictive model is equivalent with a <em>tube-model of the vocal
tract</em> (see figure on the right). A useful consequence is that from the
acoustic properties of such a tube-model, we can derive a relationship
between the physical length of the vocal tract <span class="math notranslate nohighlight">\(L\)</span> and the number of
parameters <span class="math notranslate nohighlight">\(M\)</span> of the corresponding linear predictor as</p>
<div class="math notranslate nohighlight">
\[ M = \frac{2f_sL}c, \]</div>
<p>where <span class="math notranslate nohighlight">\(f_{s}\)</span> is the sampling frequency and <span class="math notranslate nohighlight">\(c\)</span> is the speed of
sound. With an air-temperature of 35 C, the speed of sound is
<span class="math notranslate nohighlight">\(c\)</span>=350m/s. The mean length of vocal tracts for females and males are
approximately 14.1 and 16.9 cm. We can then choose to
overestimate <span class="math notranslate nohighlight">\(L\)</span>=0.17m. At a sampling frequency of 16kHz, this gives 
<span class="math notranslate nohighlight">\( M\approx 17 \)</span> . The linear predictor will catch also features of
the glottal oscillation and lip radiation, such that a useful
approximation is <span class="math notranslate nohighlight">\( M\approx
{\text{round}}\left(1.25\frac{f_s}{1000}\right) \)</span> . For different
sampling rates we then get the number of parameters <span class="math notranslate nohighlight">\(M\)</span> as</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(f_{s}\)</span></p></th>
<th class="head"><p>M</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>8 kHz</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-odd"><td><p>12.8 kHz</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-even"><td><p>16 kHz</p></td>
<td><p>20</p></td>
</tr>
</tbody>
</table>
<p>Observe however that even if a tube-model is equivalent with a linear
predictor, the relationship is non-linear and highly sensitive to small
errors. Moreover, when estimating linear predictive models from speech,
in addition to features of the vocal tract, we will also capture
features of glottal oscillation and lip-radiation It is therefore very
difficult to estimate meaningful tube-model parameters from speech. A
related sub-field of speech analysis is <span class="xref myst">glottal inverse
filtering</span>, which attempts to estimate the
glottal source from the acoustic signal. A necessary step in such
inverse filtering is to estimate the acoustic effect of the vocal tract,
that is, it is necessary to estimate the tube model.</p>
<p>A tube model of the vocal tract consisting of constant-radius
tube-segments</p>
<p><img alt="tubemodel" src="../_images/1498892011.png" /></p>
</div>
<div class="section" id="uses-in-speech-coding">
<h2><span class="section-number">3.9.6. </span>Uses in speech coding<a class="headerlink" href="#uses-in-speech-coding" title="Permalink to this headline">¶</a></h2>
<p>Linear prediction has been highly influential especially in early speech
coders. In fact, the dominant speech coding method is <span class="xref myst">code-excited
linear prediction (CELP)</span>, which
is based on linear prediction.</p>
</div>
<div class="section" id="alternative-representations-advanced-topic">
<h2><span class="section-number">3.9.7. </span>Alternative representations (advanced topic)<a class="headerlink" href="#alternative-representations-advanced-topic" title="Permalink to this headline">¶</a></h2>
<p>Suppose scalars <span class="math notranslate nohighlight">\(a_{m,k}\)</span>, are the coefficients of an <span class="math notranslate nohighlight">\(M\)</span>th
order linear predictor. Coefficients of consecutive orders <span class="math notranslate nohighlight">\(M\)</span> and <span class="math notranslate nohighlight">\(M+1\)</span>
are then related as</p>
<div class="math notranslate nohighlight">
\[ a_{M+1,k} = a_{M,k} + \gamma_{M+1} a_{M,M+1-k}, \]</div>
<p>where the real valued scalar <span class="math notranslate nohighlight">\( \gamma_{M}\in(-1,+1) \)</span> is the
<span class="math notranslate nohighlight">\(M\)</span>th <a class="reference external" href="https://en.wikipedia.org/wiki/Reflection_coefficient">reflection
coefficient</a>. This
formulation is the basis for the <a class="reference external" href="https://en.wikipedia.org/wiki/Levinson_recursion">Levinson-Durbin
algorithm</a> which can
be used to solve the linear predictive coefficients. In a physical
sense, reflection coefficients describe the amount of the acoustic wave
which is reflected back in each junction of the tube-model. In other
words, there is a relationship between the <em>cross-sectional areas</em>
<span class="math notranslate nohighlight">\(S_{k}\)</span> of each tube-segment and the reflection coefficients as</p>
<div class="math notranslate nohighlight">
\[ \gamma_k = \frac{S_k - S_{k+1}}{S_k + S_{k+1}}. \]</div>
<p>Furthermore, the logarithmic ratio of cross-sectional areas, also known
as the <a class="reference external" href="https://en.wikipedia.org/wiki/Log_area_ratio"><em>log-area
ratios</em></a>, are defined as</p>
<div class="math notranslate nohighlight">
\[ A_k = \log\frac{S_k}{S_{k+1}} =
\log\frac{1-\gamma_k}{1+\gamma_k}. \]</div>
<p>This form has been used in coding of linear predictive models, but is
today mostly of historical interest.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Representations"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Melcepstrum.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3.8. </span>The cepstrum, mel-cepstrum and mel-frequency cepstral coefficients (MFCCs)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Fundamental_frequency_F0.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.10. </span>Fundamental frequency (F0)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tom Bäckström, Okko Räsänen, Abraham Zewoudie, Pablo Pérez Zarazaga, Liisa Koivusalo, Sneha Das<br/>
    
      <div class="extra_footer">
        <p>
<img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" style="border-width: 0;" alt="Creative Commons License" />
This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>