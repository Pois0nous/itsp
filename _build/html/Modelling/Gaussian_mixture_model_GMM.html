
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.5. Gaussian mixture model (GMM) &#8212; Introduction to Speech Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.6. Neural networks" href="Neural_networks.html" />
    <link rel="prev" title="5.4. Vector quantization (VQ)" href="Vector_quantization_VQ.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Speech Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Introduction to Speech Processing
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Preface.html">
   1. Preface
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Introduction.html">
   2. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Why_speech_processing.html">
     2.1. Why speech processing?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Speech_production_and_acoustic_properties.html">
     2.2. Physiological speech production
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Speech_perception">
     Speech perception (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Linguistic_structure_of_speech.html">
     2.5. Linguistic structure of speech
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Speech-language_pathology">
     Speech-language pathology (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Applications_and_systems_structures.html">
     2.6. Applications and systems structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="http://pressbooks-dev.oer.hawaii.edu/messageprocessing/">
     Social and cognitive processes in human communication (external)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Representations/Representations.html">
   3. Basic Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Waveform.html">
     3.1. Waveform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Windowing.html">
     3.2. Windowing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Signal_energy_loudness_and_decibel.html">
     3.3. Signal energy, loudness and decibel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Spectrogram_and_the_STFT.html">
     3.4. Spectrogram and the STFT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Autocorrelation_and_autocovariance.html">
     3.5. Autocorrelation and autocovariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Cepstrum_and_MFCC.html">
     3.6. Cepstrum and MFCC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Linear_prediction.html">
     3.7. Linear prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Fundamental_frequency_F0.html">
     3.8. Fundamental frequency (F0)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Zero-crossing_rate.html">
     3.9. Zero-crossing rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Deltas_and_Delta-deltas.html">
     3.10. Deltas and Delta-deltas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Pitch-Synchoronous_Overlap-Add_PSOLA.html">
     3.11. Pitch-Synchoronous Overlap-Add (PSOLA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Jitter_and_shimmer.html">
     3.12. Jitter and shimmer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Crest_factor">
     https://en.wikipedia.org/wiki/Crest_factor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Pre-processing.html">
   4. Pre-processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Preprocessing/Pre-emphasis.html">
     4.1. Pre-emphasis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Noise_gate">
     Noise gate (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Dynamic_range_compression">
     Dynamic Range Compression (Wikipedia)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../Modelling_tools_in_speech_processing.html">
   5. Modelling tools in speech processing
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Source_modelling_and_perceptual_modelling.html">
     5.1. Source modelling and perceptual modelling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear_regression.html">
     5.2. Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Sub-space_models.html">
     5.3. Sub-space models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Vector_quantization_VQ.html">
     5.4. Vector quantization (VQ)
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     5.5. Gaussian mixture model (GMM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Neural_networks.html">
     5.6. Neural networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Non-negative_Matrix_and_Tensor_Factorization.html">
     5.7. Non-negative Matrix and Tensor Factorization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Evaluation_of_speech_processing_methods.html">
   6. Evaluation of speech processing methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Subjective_quality_evaluation.html">
     6.1. Subjective quality evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Objective_quality_evaluation.html">
     6.2. Objective quality evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Other_performance_measures.html">
     6.3. Other performance measures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Analysis_of_evaluation_results.html">
     6.4. Analysis of evaluation results
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_analysis.html">
   7. Speech analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Analysis/Fundamental_frequency_estimation.html">
     7.1. Fundamental frequency estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Voice_analysis">
     Voice and speech analysis (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Analysis/Measurements_for_medical_applications.html">
     7.2. Measurements for medical applications
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference external" href="https://en.wikipedia.org/wiki/Electroglottograph">
       Electroglottography (Wikipedia)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference external" href="https://en.wikipedia.org/wiki/Videokymography">
       Videokymography (Wikipedia)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Analysis/Inverse_filtering_for_glottal_activity_estimation.html">
       7.2.1. Inverse filtering for glottal activity estimation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Analysis/Forensic_analysis.html">
     7.3. Forensic analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Recognition_tasks_in_speech_processing.html">
   8. Recognition tasks in speech processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Voice_activity_detection_VAD.html">
     8.1. Voice activity detection (VAD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Wake-word_and_keyword_spotting.html">
     8.2. Wake-word and keyword spotting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speech_Recognition.html">
     8.3. Speech Recognition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speaker_Recognition_and_Verification.html">
     8.4. Speaker Recognition and Verification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speaker_Diarization.html">
     8.5. Speaker Diarization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Paralinguistic_speech_processing.html">
     8.6. Paralinguistic speech processing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_Synthesis.html">
   9. Speech Synthesis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Synthesis/Concatenative_speech_synthesis.html">
     9.2. Concatenative speech synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Synthesis/Statistical_parametric_speech_synthesis.html">
     9.3. Statistical parametric speech synthesis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Transmission_storage_and_telecommunication.html">
   10. Transmission, storage and telecommunication
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Design_goals.html">
     10.1. Design goals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Basic_tools.html">
     10.2. Basic tools
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Transmission/Modified_discrete_cosine_transform_MDCT.html">
     10.3. Modified discrete cosine transform (MDCT)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transmission/Entropy_coding.html">
       10.3.4. Entropy coding
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transmission/Perceptual_modelling_in_speech_and_audio_coding.html">
       10.3.5. Perceptual modelling in speech and audio coding
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Code-excited_linear_prediction_CELP.html">
     10.4. Code-excited linear prediction (CELP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Frequency-domain_coding.html">
     10.5. Frequency-domain coding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_enhancement.html">
   11. Speech enhancement
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Noise_attenuation.html">
     11.1. Noise attenuation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Echo_cancellation.html">
     11.2. Echo cancellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Bandwidth_extension_BWE.html">
     11.3. Bandwidth extension (BWE)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Multi-channel_speech_enhancement_and_beamforming.html">
     11.4. Multi-channel speech enhancement and beamforming
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://landbot.io/blog/guide-to-conversational-design/">
   Chatbots / Conversational design (external link)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Computational_models_of_human_language_processing.html">
   12. Computational models of human language processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Security_and_privacy_in_speech_technology.html">
   13. Security and privacy in speech technology
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Modelling/Gaussian_mixture_model_GMM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   5.5.1. Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-definition">
   5.5.2. Model definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   5.5.3. Applications
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Gaussian mixture model (GMM)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   5.5.1. Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-definition">
   5.5.2. Model definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   5.5.3. Applications
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="gaussian-mixture-model-gmm">
<h1><span class="section-number">5.5. </span>Gaussian mixture model (GMM)<a class="headerlink" href="#gaussian-mixture-model-gmm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="motivation">
<h2><span class="section-number">5.5.1. </span>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Where approaches such as <a class="reference internal" href="Linear_regression.html"><span class="doc std std-doc">linear regression</span></a>
and <a class="reference internal" href="Sub-space_models.html"><span class="doc std std-doc">sub-space models</span></a> are based on reducing the
dimensionality of a signal to capture the essential information in a
signal, in many cases we want to model the full range of possible
signals. For that purpose we can design models the <em>statistical
distribution</em> of the signal. For example, it is possible to model a
signal as a <a class="reference external" href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian
process</a>, where every
observation has a (multivariate) Gaussian (normal) distribution.</p>
<p>Speech signals however feature much more structure than simple Gaussian
processes. For example voiced signals are very different from unvoiced
signals, and within both voiced and unvoiced signals we have a multitude
of distinct groups of utterances whose statistical characteristics are
clearly different. Modelling them all with a Gaussian process would
ignore such structures and the model would therefore be inefficient.</p>
<p><em><a class="reference external" href="https://en.wikipedia.org/wiki/Mixture_model">Mixture models</a></em> is a
type of models, where we assume that the signal under study consists of
several distinct classes, where each class has its own unique
statistical model. That is, for example the statistics of voiced sounds
is clearly different from those of unvoiced sounds. We model each class
with its own distribution and their joint distribution is the weighted
sum of the class distributions. The weights of each distribution
correspond to the frequency with which they appear in the signal. So if
unvoiced signals would in some hypothetical language constitute 30% of
all speech sounds, then the weight of the unvoiced class would be 0.3.</p>
<p>The most typical mixture model structure uses Gaussian (normal)
distributions for each of the classes, so that the whole model is known
as a <em>Gaussian mixture model</em> (GMM). Depending on application the
class-distributions can obviously take other forms than Gaussian, for
example a Beta mixture model could be used if the individual classes
follow the Beta distribution. In this document we however focus on
Gaussian mixture models because it is most common among mixture models
and demonstrates application in an accessible way.</p>
</div>
<div class="section" id="model-definition">
<h2><span class="section-number">5.5.2. </span>Model definition<a class="headerlink" href="#model-definition" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">multivariate normal
distribution</a>
for a variable <span class="math notranslate nohighlight">\(x\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[ f\left(x;\Sigma,\mu\right) =
\frac{1}{\sqrt{\left(2\pi\right)^N \|\Sigma\|}}
\exp\left[-\frac12 (x-\mu)^T \Sigma^{-1}(x-\mu)\right], \]</div>
<p>where <span class="math notranslate nohighlight">\( \Sigma \)</span> and  <span class="math notranslate nohighlight">\( \mu \)</span> are the covariance and mean of
the process, respectively, with <span class="math notranslate nohighlight">\(N\)</span> dimensions. In other words, this is
the familiar Gaussian process for vectors <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Suppose then that we have <span class="math notranslate nohighlight">\(K\)</span> classes in the signal, where each class
has its own covariance and mean <span class="math notranslate nohighlight">\( \Sigma_k \)</span> and  <span class="math notranslate nohighlight">\( \mu_k. \)</span>
The <em>Gaussian mixture model</em> is then defined as</p>
<div class="math notranslate nohighlight">
\[ \boxed{f\left(x\right) = \sum_{k=1}^K \alpha_k f\left(x;
\Sigma_k,\mu_k\right),} \]</div>
<p>where the weights <span class="math notranslate nohighlight">\( \alpha_k \)</span> add up to unity <span class="math notranslate nohighlight">\( \sum_{k=1}^K
\alpha_k=1. \)</span></p>
</div>
<div class="section" id="applications">
<h2><span class="section-number">5.5.3. </span>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>In recognition/classification applications, we can, for example,
model a system which has two distinct states (like speech and noise)
and train a GMM with mixture components matching those states. When
receiving a microphone signal, we can then determine the likelihood
of each mixture component and thus obtain the likelihood that the
signal is speech or noise.</p></li>
<li><p>In <span class="xref myst">transmission
applications</span>, our
objective is to model the signal such that we can transmit likely
signals with a small amount of bits and unlikely signals with a
large number of bits. If we train a GMM on a speech database, we can
determine which signals are speech-like, such that those can be
transmitted with a low number of bits.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Modelling"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Vector_quantization_VQ.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">5.4. </span>Vector quantization (VQ)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Neural_networks.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.6. </span>Neural networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tom Bäckström, Okko Räsänen, Abraham Zewoudie, Pablo Pérez Zarazaga, Liisa Koivusalo, Sneha Das<br/>
    
      <div class="extra_footer">
        <p>
<img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" style="border-width: 0;" alt="Creative Commons License" />
This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>