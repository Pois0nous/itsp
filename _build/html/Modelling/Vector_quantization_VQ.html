
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.4. Vector quantization (VQ) &#8212; Introduction to Speech Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.5. Gaussian mixture model (GMM)" href="Gaussian_mixture_model_GMM.html" />
    <link rel="prev" title="5.3. Sub-space models" href="Sub-space_models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Speech Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Introduction to Speech Processing
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Preface.html">
   1. Preface
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Introduction.html">
   2. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Why_speech_processing.html">
     2.1. Why speech processing?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Speech_production_and_acoustic_properties.html">
     2.2. Physiological speech production
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Speech_perception">
     Speech perception (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Linguistic_structure_of_speech.html">
     2.5. Linguistic structure of speech
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Speech-language_pathology">
     Speech-language pathology (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Applications_and_systems_structures.html">
     2.6. Applications and systems structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="http://pressbooks-dev.oer.hawaii.edu/messageprocessing/">
     Social and cognitive processes in human communication (external)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Representations/Representations.html">
   3. Basic Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Waveform.html">
     3.1. Waveform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Windowing.html">
     3.2. Windowing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Signal_energy_loudness_and_decibel.html">
     3.3. Signal energy, loudness and decibel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Spectrogram_and_the_STFT.html">
     3.4. Spectrogram and the STFT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Autocorrelation_and_autocovariance.html">
     3.5. Autocorrelation and autocovariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Cepstrum_and_MFCC.html">
     3.6. Cepstrum and MFCC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Linear_prediction.html">
     3.7. Linear prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Fundamental_frequency_F0.html">
     3.8. Fundamental frequency (F0)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Zero-crossing_rate.html">
     3.9. Zero-crossing rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Deltas_and_Delta-deltas.html">
     3.10. Deltas and Delta-deltas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Pitch-Synchoronous_Overlap-Add_PSOLA.html">
     3.11. Pitch-Synchoronous Overlap-Add (PSOLA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Representations/Jitter_and_shimmer.html">
     3.12. Jitter and shimmer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Crest_factor">
     https://en.wikipedia.org/wiki/Crest_factor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Pre-processing.html">
   4. Pre-processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Preprocessing/Pre-emphasis.html">
     4.1. Pre-emphasis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Noise_gate">
     Noise gate (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Dynamic_range_compression">
     Dynamic Range Compression (Wikipedia)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../Modelling_tools_in_speech_processing.html">
   5. Modelling tools in speech processing
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Source_modelling_and_perceptual_modelling.html">
     5.1. Source modelling and perceptual modelling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear_regression.html">
     5.2. Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Sub-space_models.html">
     5.3. Sub-space models
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     5.4. Vector quantization (VQ)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Gaussian_mixture_model_GMM.html">
     5.5. Gaussian mixture model (GMM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Neural_networks.html">
     5.6. Neural networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Non-negative_Matrix_and_Tensor_Factorization.html">
     5.7. Non-negative Matrix and Tensor Factorization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Evaluation_of_speech_processing_methods.html">
   6. Evaluation of speech processing methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Subjective_quality_evaluation.html">
     6.1. Subjective quality evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Objective_quality_evaluation.html">
     6.2. Objective quality evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Other_performance_measures.html">
     6.3. Other performance measures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Evaluation/Analysis_of_evaluation_results.html">
     6.4. Analysis of evaluation results
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_analysis.html">
   7. Speech analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Analysis/Fundamental_frequency_estimation.html">
     7.1. Fundamental frequency estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Analysis/Inverse_filtering_for_glottal_activity_estimation.html">
     7.2. Inverse filtering for glottal activity estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://en.wikipedia.org/wiki/Voice_analysis">
     Voice and speech analysis (Wikipedia)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Analysis/Measurements_for_medical_applications.html">
     7.3. Measurements for medical applications
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference external" href="https://en.wikipedia.org/wiki/Electroglottograph">
       Electroglottography (Wikipedia)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference external" href="https://en.wikipedia.org/wiki/Videokymography">
       Videokymography (Wikipedia)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Analysis/Glottal_inverse_filtering.html">
       7.3.1. Glottal inverse filtering
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Analysis/Forensic_analysis.html">
     7.4. Forensic analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Recognition_tasks_in_speech_processing.html">
   8. Recognition tasks in speech processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Voice_activity_detection_VAD.html">
     8.1. Voice activity detection (VAD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Wake-word_and_keyword_spotting.html">
     8.2. Wake-word and keyword spotting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speech_Recognition.html">
     8.3. Speech Recognition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speaker_Recognition_and_Verification.html">
     8.4. Speaker Recognition and Verification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Speaker_Diarization.html">
     8.5. Speaker Diarization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Recognition/Paralinguistic_speech_processing.html">
     8.6. Paralinguistic speech processing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_Synthesis.html">
   9. Speech Synthesis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Synthesis/Concatenative_speech_synthesis.html">
     9.2. Concatenative speech synthesis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Synthesis/Statistical_parametric_speech_synthesis.html">
     9.3. Statistical parametric speech synthesis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Transmission_storage_and_telecommunication.html">
   10. Transmission, storage and telecommunication
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Design_goals.html">
     10.1. Design goals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Basic_tools.html">
     10.2. Basic tools
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Transmission/Modified_discrete_cosine_transform_MDCT.html">
     10.3. Modified discrete cosine transform (MDCT)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transmission/Entropy_coding.html">
       10.3.4. Entropy coding
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transmission/Perceptual_modelling_in_speech_and_audio_coding.html">
       10.3.5. Perceptual modelling in speech and audio coding
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Code-excited_linear_prediction_CELP.html">
     10.4. Code-excited linear prediction (CELP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Transmission/Frequency-domain_coding.html">
     10.5. Frequency-domain coding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Speech_enhancement.html">
   11. Speech enhancement
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Noise_attenuation.html">
     11.1. Noise attenuation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Echo_cancellation.html">
     11.2. Echo cancellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Bandwidth_extension_BWE.html">
     11.3. Bandwidth extension (BWE)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Enhancement/Multi-channel_speech_enhancement_and_beamforming.html">
     11.4. Multi-channel speech enhancement and beamforming
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://landbot.io/blog/guide-to-conversational-design/">
   Chatbots / Conversational design (external link)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Computational_models_of_human_language_processing.html">
   12. Computational models of human language processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Security_and_privacy_in_speech_technology.html">
   13. Security and privacy in speech technology
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Modelling/Vector_quantization_VQ.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metric-for-codebook-quality">
   5.4.1. Metric for codebook quality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#codebook-optimization">
   5.4.2. Codebook optimization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#expectation-maximization-em">
     5.4.2.1. Expectation maximization (EM)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-with-machine-learning-platforms">
     5.4.2.2. Optimization with machine learning platforms
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algorithmic-complexity">
   5.4.3. Algorithmic complexity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   5.4.4. Applications
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#discussion">
   5.4.5. Discussion
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Vector quantization (VQ)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metric-for-codebook-quality">
   5.4.1. Metric for codebook quality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#codebook-optimization">
   5.4.2. Codebook optimization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#expectation-maximization-em">
     5.4.2.1. Expectation maximization (EM)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization-with-machine-learning-platforms">
     5.4.2.2. Optimization with machine learning platforms
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algorithmic-complexity">
   5.4.3. Algorithmic complexity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   5.4.4. Applications
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#discussion">
   5.4.5. Discussion
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="vector-quantization-vq">
<h1><span class="section-number">5.4. </span>Vector quantization (VQ)<a class="headerlink" href="#vector-quantization-vq" title="Permalink to this headline">¶</a></h1>
<p>Suppose you have recorded sounds at different locations and want to
categorize them into similar groups. In other words, you have a
stochastic vector <span class="math notranslate nohighlight">\(x\)</span> which you want to characterize with a simple
description. For example, categories could correspond to office, street,
hallway and cafeteria. A classic way for this task is to choose template
vectors <span class="math notranslate nohighlight">\(c_{k}\)</span>, which represents a typical sound in each
environment <span class="math notranslate nohighlight">\(k\)</span>. To categorize the sounds, you then find that template
vector which is closest to your recording <span class="math notranslate nohighlight">\(x\)</span>. In mathematical notation,
you search for a <span class="math notranslate nohighlight">\(k^{^*}\)</span> by</p>
<div class="math notranslate nohighlight">
\[ k^* = \arg\min_k \|x-c_k\|^2. \]</div>
<p>The above expression thus calculates the squared error between <span class="math notranslate nohighlight">\(x \)</span> and
each of the vectors <span class="math notranslate nohighlight">\(c_{k}\)</span> and chooses the index <span class="math notranslate nohighlight">\(k \)</span> of the
vector with the smallest error. The vectors <span class="math notranslate nohighlight">\(c_{k}\)</span> then
represent a codebook and the vector <span class="math notranslate nohighlight">\(x\)</span> is quantized to
<span class="math notranslate nohighlight">\(c_{k^*}\)</span>. This is the basic idea behind <em>vector quantization,</em>
which is also known as <em>k-means</em>.</p>
<p>A illustration of a simple vector codebook is shown on the right. The
input data is a Gaussian distribution shown with grey dots and the
codebook vectors <span class="math notranslate nohighlight">\(c_{k}\)</span> with red circles. For each input vector
we thus search for the nearest codebook vector and the borders of the
regions where input vectors are assigned to a particular codebook vector
are illustrated with blue lines. These regions are known as <a class="reference external" href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi
regions</a> and the blue
lines are the decision-boundaries between codebook vectors.</p>
<p><img alt="vq.png" src="../_images/175511825.png" /></p>
<p>Example of a codebook for a 2D Gaussian with 16 code vectors.</p>
<div class="section" id="metric-for-codebook-quality">
<h2><span class="section-number">5.4.1. </span>Metric for codebook quality<a class="headerlink" href="#metric-for-codebook-quality" title="Permalink to this headline">¶</a></h2>
<p>Suppose then that you have a large collection of
vectors <span class="math notranslate nohighlight">\(x_{h}\)</span>, and you want to find out how well this codebook
represents the input data. The expectation of the squared error is
approximately the mean over your data, such that</p>
<div class="math notranslate nohighlight">
\[ E_h\left[ \min_k \|x_h-c_k\|^2 \right] \approx \frac 1N
\sum_{h=1}^N \min_k \|x_h-c_k\|^2, \]</div>
<p>where <span class="math notranslate nohighlight">\(E[ ]\)</span> is the expectation operator and <span class="math notranslate nohighlight">\(N\)</span> is the number of
input vectors <span class="math notranslate nohighlight">\(x_{h}\)</span>. Above, we thus find the codebook vector
which is closest to <span class="math notranslate nohighlight">\(x_{h}\)</span>, find its squared error and take the
expectation over all possible inputs. This is approximately equal to the
mean of those squared errors over a set of input vectors.</p>
<p>To find the best set of codebook vectors <span class="math notranslate nohighlight">\(c_{k}\)</span>, we then need
to minimize the mean squared error as</p>
<div class="math notranslate nohighlight">
\[ \{c_k^*\} := \arg\min_{\{c_k\}}\, E_h\left[ \min_k
\|x_h-c_k\|^2 \right]  \]</div>
<p>or more specifically, for a dataset as</p>
<div class="math notranslate nohighlight">
\[ \{c_k^*\} := \arg\min_{\{c_k\}} \sum_{h=1}^N \min_k
\|x_h-c_k\|^2. \]</div>
<p>Unfortunately we do not have an analytic solution for this optimization
problem, but have to use numerical, iterative methods.</p>
</div>
<div class="section" id="codebook-optimization">
<h2><span class="section-number">5.4.2. </span>Codebook optimization<a class="headerlink" href="#codebook-optimization" title="Permalink to this headline">¶</a></h2>
<div class="section" id="expectation-maximization-em">
<h3><span class="section-number">5.4.2.1. </span>Expectation maximization (EM)<a class="headerlink" href="#expectation-maximization-em" title="Permalink to this headline">¶</a></h3>
<p>Classical methods for finding the best codebook are derivatives of
expectation maximization (EM), which is based on two alternating steps:</p>
<p><em>Expectation Maximation (EM)</em> algorithm:</p>
<ol class="simple">
<li><p>For every vector <span class="math notranslate nohighlight">\(x_{h}\)</span> in a large database, find the best
codebook vector <span class="math notranslate nohighlight">\(c_{k}\)</span>.</p></li>
<li><p>For every codebook vector <span class="math notranslate nohighlight">\(c_{k}\)</span>;</p>
<ol class="simple">
<li><p>Find all vectors <span class="math notranslate nohighlight">\(x_{h}\)</span> assigned to that codevector.</p></li>
<li><p>Calculate mean of those vectors.</p></li>
<li><p>Assign the mean as a new value for the codevector.</p></li>
</ol>
</li>
<li><p>If converged then stop, otherwise go to 1.</p></li>
</ol>
<p>This algorithm is guaranteed to give a codebook at every step which is
<em>not worse</em> than the previous codebook. That is, at each iteration will
improve until it finds a local minimum, where it stops changing. The
reason is that each step in the iteration finds a partial best-solution.
In the first step, we find the best matching codebook vectors for each
data vectors <span class="math notranslate nohighlight">\(x_{h}\)</span>. In the second step, we find the
within-category mean. That is, the new mean is more accurate than the
previous codevector in that it reduces the average squared error. If the
mean is equal to the previous codevector, then there is no improvement.</p>
<p>As noted above, this algorithm is the basis to most vector quantization
codebook optimization algorithms. There are a multiple reasons why this
simple algorithm is usually not sufficient alone. Most importantly, the
above algorithm is slow to converge to a stable solution <em>and</em> it often
finds a local minimum instead of a global minimum.</p>
<p>To improve performance, we can apply several heuristic approaches. For
example, we can start with a small codebook <span class="math notranslate nohighlight">\( \{ c_k \}_{k=1}^K \)</span>
of <span class="math notranslate nohighlight">\(K\)</span> elements and optimize it with the EM algorithm. We then split the
codebook into two, offset by a small delta <span class="math notranslate nohighlight">\(d\)</span>, such that <span class="math notranslate nohighlight">\(
\|d\|&lt;\epsilon \)</span> and make the new codebook <span class="math notranslate nohighlight">\( \{ \hat c_k
\}_{k=1}^{2K} := \{ c_k,\, c_k+d \}_{k=1}^K \)</span> of 2<span class="math notranslate nohighlight">\(K\)</span> elements.
We then rerun the EM algorithm on the new codebook. The codebook thus
doubles in size at every iteration and we continue until we have the
desired codebook size.</p>
<p>The advantage of this approach is that it focuses attention to the big
bulk of datapoints <span class="math notranslate nohighlight">\(x_{k}\)</span>, and ignores outliers. The outcome is
then expected to be more stable and the likelihood of converging to a
local minimum is smaller. The downside is that with this approach it is
then more difficult to find small separated islands. That is, because
the initial codebook is near the center of the whole mass of datapoints,
adding a small delta to the codebook vectors keeps the new codevectors
near the center-of-mass.</p>
<p>Conversely, we can start with a large codebook, say treat the whole
input database <span class="math notranslate nohighlight">\(x_{k}\)</span> as a codebook. We can then iteratively
merge pairs of points which are close to each other, until the codebook
is reduced to the desired size. Needless to say, this will be a slow
process if the database is large, but will be very efficient in finding
separated islands of points.</p>
<p>In any case, optimization of vector codebooks is a difficult task and we
have no practical algorithms which would be guaranteed to find the
global optimum. Like in many other machine learning problems, optimizing
the codebook is very much about learning to know your data. You should
first use one algorithm and then analyse the output to find out what can
be improved, and keep repeating this optimization and analyse process
until the output is sufficiently good.</p>
</div>
<div class="section" id="optimization-with-machine-learning-platforms">
<h3><span class="section-number">5.4.2.2. </span>Optimization with machine learning platforms<a class="headerlink" href="#optimization-with-machine-learning-platforms" title="Permalink to this headline">¶</a></h3>
<p>A modern approach to modelling is <a class="reference internal" href="Neural_networks.html"><span class="doc std std-doc">machine learning</span></a>, where complex phenomena are modelled with neural networks. Typically they are trained with <a class="reference external" href="https://en.wikipedia.org/wiki/Gradient_descent">gradient-descent</a> type methods, where parameters are iteratively nudged towards the minimum, by following the steepest gradient. Since such gradients can be automatically derived on machine learning platforms (using the <a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a>), they can be applied on very complex models. Consequently, they have become very popular and succesful.</p>
<p>The same type of training can be readily applied to vector quantizers as well. However, there is a practical problem with this approach. Estimation of the gradients of the parameters with the chain-rule requires that <em>all</em> intermediate gradients are non-zero. Quantizers are however piece-wise constant such that their gradients are uniformly zero, thus disabling the chain rule and gradient descent for all parameters which lie behind the quantizer in the computational graph. A practical solution is known as pass-through, where gradients are passed unchanged through the quantizer. This approximation is simple to implement and provides often adequate performance.</p>
<p>While this approach converges slower than the EM-algorithm, it is often beneficial since it allows optimization of an entire system to a single goal. That is, if we have several modules in a system, it is beneficial if their joint interaction is taken into account in the optimization. If modules are optimized independently, it is difficult to anticpate all interactions and the system performance can remain far from optimal.</p>
</div>
</div>
<div class="section" id="algorithmic-complexity">
<h2><span class="section-number">5.4.3. </span>Algorithmic complexity<a class="headerlink" href="#algorithmic-complexity" title="Permalink to this headline">¶</a></h2>
<p>Vector quantization is manageable for relatively small codebooks of,
say, <span class="math notranslate nohighlight">\(K=32\)</span> codevectors. That corresponds to 5 bits of information. For
many applications, that does not give sufficient accuracy - the mean
squared error is too large. For example, the linear predictive models in
speech coding could be quantized with 30 bits, which corresponds to <span class="math notranslate nohighlight">\(
K=2^{30}\approx 10^9 \)</span> codevectors. To find the best codevector for a
vector <span class="math notranslate nohighlight">\(x\)</span> of length <span class="math notranslate nohighlight">\(N=16\)</span>, we would then need to calculate the
distance between every codebook vector and <span class="math notranslate nohighlight">\(x\)</span>, which amounts to
approximately <span class="math notranslate nohighlight">\( 16\times10^9= 1.6\times10^{10} \)</span> operations. That
is infeasible in on-line applications on mobile devices. Instead, we
need to find a simpler method which retains the best aspects of the
algorithm, but reduces algorithmic complexity.</p>
<p>A heuristic approach is to use successive codebooks, where at each
iteration, we quantize the error of the last iteration. That is, let’s
say that on the first iteration we have 8 bits, corresponding to a
codebook <span class="math notranslate nohighlight">\(c_{k}\)</span> of <span class="math notranslate nohighlight">\(K=256\)</span> vectors. We find the best matching
codevector <span class="math notranslate nohighlight">\(c_{k^*}\)</span> and calculate the residual <span class="math notranslate nohighlight">\(
x':=x-c_{k^*} \)</span> . In the second stage, we would then find the best
matching vector for <span class="math notranslate nohighlight">\(x'\)</span> from a second codebook <span class="math notranslate nohighlight">\(c_{k}'\)</span>. We can
add as many layers of codebooks as we want until the desired number of
bits has been consumed. This approach is known as a <em>multi-stage vector
quantizer</em>.</p>
<p>Where ordinary vector quantization can find the optimal solution, split
vector quantization generally does not give a global optimum. It does
give good solutions, though, but with an algorithmic complexity which
very much lower than ordinary vector quantization. For example, in the
above example of 30 bits, we could assign three consecutive layers of
codebooks with 10 bits / <span class="math notranslate nohighlight">\(K=1024\)</span> each, such that the overall complexity
is <span class="math notranslate nohighlight">\( 3\times 16\times 2^{10} \approx 5\times10^4, \)</span> which gives
an improvement with a factor of <span class="math notranslate nohighlight">\( 3.5\times10^5. \)</span> Given that the
reduction in accuracy is manageable, this is a major improvement in
complexity.</p>
</div>
<div class="section" id="applications">
<h2><span class="section-number">5.4.4. </span>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<p>Probably the most important application where vector quantization is
used in speech processing, is <span class="xref myst">speech
coding</span> with <span class="xref myst">Code-excited
linear prediction (CELP)</span>, where</p>
<ul class="simple">
<li><p><span class="xref myst">linear predictive coefficients (LPC)</span> are
transformed to line spectral frequencies (LSFs), which are often
encoded with multi-stage vector quantizers.</p></li>
<li><p>gains (signal energy) of the residual and long term prediction are
jointly encoded with a single stage vector quantizer.</p></li>
</ul>
<p>Other typical applications include</p>
<ul class="simple">
<li><p>In optimization of <span class="xref myst">Gaussian mixture models
(GMMs)</span>, it is useful to use vector
quantization to find a first-guess of the means of each mixture.</p></li>
</ul>
</div>
<div class="section" id="discussion">
<h2><span class="section-number">5.4.5. </span>Discussion<a class="headerlink" href="#discussion" title="Permalink to this headline">¶</a></h2>
<p>The benefit of vector quantization is that it is a simple algorithm
which gives high accuracy. In fact, for quantizing complicated data,
vector quantization is (in theory) optimal in fixed-rate coding
applications. It is simple in the sense that an experienced engineer can
implement it in a matter of hours. Downsides with vector quantization
include</p>
<ul class="simple">
<li><p>Complexity; for accurate quantization you need prohibitively large
codebooks. The method therefore does not scale up nicely to big
problems.</p></li>
<li><p>Difficult optimization;</p>
<ul>
<li><p>Training data; The amount of data needed to optimize a vector
codebook is large. Each codebook vector must be assigned to a
large number of data vectors, such that calculation of the mean
(in the EM algorithm) is meaningful.</p></li>
<li><p>Convergence; we have no assurance that optimization algorithms
find the global optimum and we have no assurance that local
minima are “good enough”.</p></li>
</ul>
</li>
<li><p>Lack of flexibility; the codebook has a fixed size. If we would like
to use codebooks of different sizes, for example, if we want to
transmit data with a variable bit-rate, then we have to optimize and
store a large codebook for <em>every possible bitrate</em>.</p></li>
<li><p>Blindness to inherent structures; this model describes data with a
codebook, without any deeper understanding of what the data looks
like within each category. For example, say we have two classes,
speech and non-speech. Even if speech is very flexible, the
non-speech class is much, much larger. Speech is a very small subset
of all possible sounds. Therefore, the within-class variance will be
much larger in the non-speech class. Consequently, the accuracy in
the non-speech class would be much lower.<br />
As a consequence, we would be tempted to increase the number of
codevectors such that we get uniform accuracy in both classes. But
then we loose the correspondence between codevectors and natural
descriptions of the signal.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Modelling"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Sub-space_models.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">5.3. </span>Sub-space models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Gaussian_mixture_model_GMM.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.5. </span>Gaussian mixture model (GMM)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tom Bäckström, Okko Räsänen, Abraham Zewoudie, Pablo Pérez Zarazaga, Liisa Koivusalo, Sneha Das<br/>
    
      <div class="extra_footer">
        <p>
<img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" style="border-width: 0;" alt="Creative Commons License" />
This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>