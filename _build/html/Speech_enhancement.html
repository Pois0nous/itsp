
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Speech enhancement &#8212; Introduction to Speech Processing</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Introduction to Speech Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="README.html">
   Introduction to Speech Processing
  </a>
 </li>
</ul>
    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Speech_enhancement.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Speech enhancement</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="speech-enhancement">
<h1>Speech enhancement<a class="headerlink" href="#speech-enhancement" title="Permalink to this headline">Â¶</a></h1>
<div class="contentLayout2">
<div class="columnLayout two-equal" layout="two-equal">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p>When using speech technology in real environments, we are often faced
with less than perfect signal quality. For example, if you make a phone
call at cafeteria, typically you have plenty of other people speaking in
the background, there could be music playing and the room itself can
have reverberation. Such effects distort the desired speech signal such
that the receiving end, the desired speech sounds less pleasant,
requires more effort to understand or at the worst case, it becomes less
intelligible. <em>Speech enhancement</em> refers to methods which try to reduce
such distortions, to make speech sounds more pleasant, reduce listening
effort and improve intelligibility.</p>
<p>The most prominent categories of speech enhancement are:</p>
<ol class="simple">
<li><p><a class="reference internal" href="Noise_attenuation.html"><span class="doc std std-doc">Noise attenuation</span></a>, where we try to extract the
desired speech signalm when distorted by background noise(s).</p></li>
<li><p><span class="xref myst">Echo cancellation</span> and feedback cancellation are
used when the sound played from a loudspeaker is picked up by a
microphone distorting the desired signal.</p></li>
<li><p><span class="xref myst">Bandwidth extensions</span> refers to methods
which convert a signal at a lower sampling rate to a higher sampling
rate and fills the missing range of the spectrum with some plausible
content.</p></li>
<li><p>Dereverberation refers to methods which attenuate the effect of room
acoustics on the desired signal.</p></li>
<li><p>Source separation methods try to extract sounds of single sources
from a mixture, for example, in the classical cocktail-party
problem, we would like to isolate single speakers when multiple
people are talking at the same time.</p></li>
<li><p><span class="xref myst">Beamforming</span>
refers to spatially selective methods, where the objective is
isolate sounds coming from a particular direction, by using the
information about the spatial separation of a set of microphones.</p></li>
</ol>
<p>The objective of speech enhancement however requires a bit more
consideration. In its most classical form, the objective is to extract a
clean speech signal from a distorted mixture, where the distortions can
be background and sensor noises, as well as room reverberation. Here the
clean reference signal is considered to be that signal which would be
rerecorded with a microphone close to the speaker, which does not
contain said noises or reverberation. It is then clear that it will be
challenging to obtain realistic data, since even a microphone close to
the speaker will usually contain background noises and effect of
reverberation. For development of methods, it is therefore often
difficult to obtain data which would accurately correspond to a
realistic situation. In any case, a typical objective would be to
improve the signal to noise ratio (with or without perceptual weighting)
as much as possible.</p>
<p>A more challenging scenario is when two or more persons are speaking in
the same acoustic environment. The second speaker can then be viewed as
a competing speaker (undesired source) or as a discussion partner
(desired source). Even if the two speakers are in an interaction with
each other, then often they will speak on top of each other, even if
stereotypically we think of a dialogue as a non-overlapping back and
forth exchange of non-overlapping arguments. If we want to separate
between the two speakers, then overlaps are difficult, because the
statistics of the both speech signals will be rather similar, whereas
noise signals with distinct statistics are easier to attenuate.</p>
<p>Sometimes we do not want to remove all distortions entirely, but just
attenuate their effect. Completely removing artefacts can sometimes make
the signal sound unnatural and besides removing distortions, processing
methods also almost always distorts the desired signal. Therefore, to
retain a natural-sounding signal and to minimize distortion of the
desired speech signal, we often limit the extent to which distortions
are removed.</p>
<p>A further aspect of enhancement is intelligibility and pleasantness; as
a starting point, observe that the speech of some people is by nature
difficult to understand or otherwise just annoying (unpleasant). It then
conceivable that we device some processing which improves the speech
signal to better than the original. What âsounds betterâ is however a
difficult concept, since we do not have unambiguous measures for âhow
good it soundsâ and opinions between listeners will certainly diverge.</p>
<p>Intelligibility with regard to human listeners is similarly complicated
as pleasantness, but luckily, we can use speech recognition engines to
obtain objective measures. That is, if we give noisy and improved speech
signals to a speech recognizer, we can determine the recognition
performance in both cases to estimate the benefit obtained with our
processing.</p>
</div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tom BÃ¤ckstrÃ¶m, Okko RÃ¤sÃ¤nen, Abraham Zewoudie, Pablo PÃ©rez Zarazaga, Liisa Koivusalo, Sneha Das<br/>
    
      <div class="extra_footer">
        <p>
<img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" style="border-width: 0;" alt="Creative Commons License" />
This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>